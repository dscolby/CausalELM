<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Double Machine Learning · CausalELM.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://dscolby.github.io/CausalELM.jl/guide/doublemachinelearning/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="CausalELM.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">CausalELM.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">CausalELM</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../its/">Interrupted Time Series Estimation</a></li><li><a class="tocitem" href="../gcomputation/">G-computation</a></li><li class="is-active"><a class="tocitem" href>Double Machine Learning</a><ul class="internal"><li><a class="tocitem" href="##-Step-1:-Initialize-a-Model"><span># Step 1: Initialize a Model</span></a></li><li><a class="tocitem" href="#Step-2:-Estimate-the-Causal-Effect"><span>Step 2: Estimate the Causal Effect</span></a></li><li class="toplevel"><a class="tocitem" href="#Get-a-Summary"><span>Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model"><span>Step 4: Validate the Model</span></a></li></ul></li><li><a class="tocitem" href="../metalearners/">Metalearners</a></li></ul></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="../../reference/api/">CausalELM</a></li><li><a class="tocitem" href="../../reference/activations/">Activation Functions</a></li><li><a class="tocitem" href="../../reference/crossval/">Cross Validation</a></li><li><a class="tocitem" href="../../reference/estimation/">ATE/ATT/ITE Estimation</a></li><li><a class="tocitem" href="../../reference/metalearners/">CATE Estimation</a></li><li><a class="tocitem" href="../../reference/inference/">Inference and Summarization</a></li><li><a class="tocitem" href="../../reference/validation/">Model Validation</a></li><li><a class="tocitem" href="../../reference/metrics/">Validation Metrics</a></li><li><a class="tocitem" href="../../reference/base/">Base Models</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>Double Machine Learning</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Double Machine Learning</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dscolby/CausalELM.jl/blob/main/docs/src/guide/doublemachinelearning.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Double-Machine-Learning"><a class="docs-heading-anchor" href="#Double-Machine-Learning">Double Machine Learning</a><a id="Double-Machine-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Double-Machine-Learning" title="Permalink"></a></h1><p>Doubly robust estimation estimates separate models for the treatment and outcome variables  and weights the outcome estimates by the treatment estimates. This allows one to model more  complex, nonlinear relationships between the treatment and outcome variables. Additonally,  double machine learning is doubly robust, which meants that only one of the models has to be  specified correctly to produce an unbiased estimate of the causal effect. This  implementation also uses cross fitting to avoid regularization bias. The main steps for  using doubly robust estimation in CausalELM are below.</p><p>For more information see:     Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen,      Whitney Newey, and James Robins. &quot;Double/debiased machine learning for treatment and      structural parameters.&quot; (2018): C1-C68.</p><h2 id="-Step-1:-Initialize-a-Model"><a class="docs-heading-anchor" href="##-Step-1:-Initialize-a-Model"># Step 1: Initialize a Model</a><a id="-Step-1:-Initialize-a-Model-1"></a><a class="docs-heading-anchor-permalink" href="##-Step-1:-Initialize-a-Model" title="Permalink"></a></h2><p>The DoubleMachineLearning constructor takes four arguments, an array of covariates for the  outcome model, an array of covariates for the treatment model, a vector of outcomes, and a  vector of treatment statuses.</p><pre><code class="language-julia hljs"># Create some data with a binary treatment
X, Xₚ, Y, T =  rand(100, 5), rand(100, 4), rand(100), [rand()&lt;0.4 for i in 1:100]

dml = DoubleMachineLearning(X, Xₚ, Y, T)</code></pre><h2 id="Step-2:-Estimate-the-Causal-Effect"><a class="docs-heading-anchor" href="#Step-2:-Estimate-the-Causal-Effect">Step 2: Estimate the Causal Effect</a><a id="Step-2:-Estimate-the-Causal-Effect-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Estimate-the-Causal-Effect" title="Permalink"></a></h2><p>To estimate the causal effect, we call estimatecausaleffect! on the model above.</p><pre><code class="language-julia hljs"># we could also estimate the ATT by passing quantity_of_interest=&quot;ATT&quot;
estimate_causal_effect!(dml)</code></pre><h1 id="Get-a-Summary"><a class="docs-heading-anchor" href="#Get-a-Summary">Get a Summary</a><a id="Get-a-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Get-a-Summary" title="Permalink"></a></h1><p>We can get a summary that includes a p-value and standard error estimated via asymptotic  randomization inference by passing our model to the summarize method.</p><pre><code class="language-julia hljs">summarize(dml)</code></pre><h2 id="Step-4:-Validate-the-Model"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model">Step 4: Validate the Model</a><a id="Step-4:-Validate-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model" title="Permalink"></a></h2><p>We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model&#39;s  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  probability of treatment. If the matrix is empty, none of the observations have an estimated  zero probability of treatment, which implies the positivity assumption is satisfied.</p><p>For a thorough review of casual inference assumptions see:     Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and      Francis, 2024. </p><p>For more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research:      introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</p><pre><code class="language-julia hljs">validate(g_computer)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gcomputation/">« G-computation</a><a class="docs-footer-nextpage" href="../metalearners/">Metalearners »</a><div class="flexbox-break"></div><p class="footer-message">© 2023 Darren Colby</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Friday 5 January 2024 22:54">Friday 5 January 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
