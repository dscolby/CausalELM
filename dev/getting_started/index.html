<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting Started · causalELM</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://dscolby.github.io/CausalELM.jl/getting_started/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.jpg" alt="causalELM logo"/></a><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">causalELM</a></li><li class="is-active"><a class="tocitem" href>Getting Started</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Interrupted-Time-Series-Analysis"><span>Interrupted Time Series Analysis</span></a></li><li><a class="tocitem" href="#Step-1:-Initialize-an-interrupted-time-series-estimator"><span>Step 1: Initialize an interrupted time series estimator</span></a></li><li><a class="tocitem" href="#Step-2:-Estimate-the-Treatment-Effect"><span>Step 2: Estimate the Treatment Effect</span></a></li><li><a class="tocitem" href="#Step-3:-Get-a-Summary"><span>Step 3: Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model"><span>Step 4: Validate the Model</span></a></li><li class="toplevel"><a class="tocitem" href="#G-Computation"><span>G-Computation</span></a></li><li><a class="tocitem" href="#Step-1:-Initialize-a-Model"><span>Step 1: Initialize a Model</span></a></li><li><a class="tocitem" href="#Step-2:-Estimate-the-Causal-Effect"><span>Step 2: Estimate the Causal Effect</span></a></li><li><a class="tocitem" href="#Step-3:-Get-a-Summary-2"><span>Step 3: Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model-2"><span>Step 4: Validate the Model</span></a></li><li class="toplevel"><a class="tocitem" href="#Double-Machine-Learning"><span>Double Machine Learning</span></a></li><li><a class="tocitem" href="##-Step-1:-Initialize-a-Model"><span># Step 1: Initialize a Model</span></a></li><li><a class="tocitem" href="#Step-2:-Estimate-the-Causal-Effect-2"><span>Step 2: Estimate the Causal Effect</span></a></li><li class="toplevel"><a class="tocitem" href="#Get-a-Summary"><span>Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model-3"><span>Step 4: Validate the Model</span></a></li><li class="toplevel"><a class="tocitem" href="#Metalearners"><span>Metalearners</span></a></li><li class="toplevel"><a class="tocitem" href="#Initialize-a-Metalearner"><span>Initialize a Metalearner</span></a></li><li class="toplevel"><a class="tocitem" href="#Estimate-the-CATE"><span>Estimate the CATE</span></a></li><li class="toplevel"><a class="tocitem" href="#Get-a-Summary-2"><span>Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model-4"><span>Step 4: Validate the Model</span></a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Getting Started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting Started</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dscolby/CausalELM.jl/blob/main/docs/src/getting_started.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Deciding-Which-Estimator-to-Use"><a class="docs-heading-anchor" href="#Deciding-Which-Estimator-to-Use">Deciding Which Estimator to Use</a><a id="Deciding-Which-Estimator-to-Use-1"></a><a class="docs-heading-anchor-permalink" href="#Deciding-Which-Estimator-to-Use" title="Permalink"></a></h1><p>Which model you should use depends on what you are trying to model and the type of data you  have. The table below can serve as a useful reference when deciding which model to use for a  given dataset and causal question.</p><table><tr><th style="text-align: right">Model</th><th style="text-align: right">Struct</th><th style="text-align: right">Causal Estimands</th><th style="text-align: right">Supported Treatment Types</th><th style="text-align: right">Supported Outcome Types</th></tr><tr><td style="text-align: right">Interrupted Time Series Analysis</td><td style="text-align: right">InterruptedTimeSeries</td><td style="text-align: right">ATE, Cumulative Treatment Effect</td><td style="text-align: right">Binary</td><td style="text-align: right">Binary, Continuous</td></tr><tr><td style="text-align: right">G-computation</td><td style="text-align: right">GComputation</td><td style="text-align: right">ATE, ATT, ITT</td><td style="text-align: right">Binary</td><td style="text-align: right">Binary, Continuous, Time to Event</td></tr><tr><td style="text-align: right">Double Machine Learning</td><td style="text-align: right">DoubleMachineLearning</td><td style="text-align: right">ATE</td><td style="text-align: right">Binary, Count, Categorical, Continuous</td><td style="text-align: right">Continuous</td></tr><tr><td style="text-align: right">S-learning</td><td style="text-align: right">SLearner</td><td style="text-align: right">CATE</td><td style="text-align: right">Binary</td><td style="text-align: right">Binary, Continuous, Count</td></tr><tr><td style="text-align: right">T-learning</td><td style="text-align: right">TLearner</td><td style="text-align: right">CATE</td><td style="text-align: right">Binary</td><td style="text-align: right">Binary, Continuous</td></tr><tr><td style="text-align: right">X-learning</td><td style="text-align: right">XLearner</td><td style="text-align: right">CATE</td><td style="text-align: right">Binary</td><td style="text-align: right">Binary, Continuous, Count</td></tr><tr><td style="text-align: right">R-learning</td><td style="text-align: right">RLearner</td><td style="text-align: right">CATE</td><td style="text-align: right">Binary, Count, Categorical, Continuous</td><td style="text-align: right">Continuous</td></tr></table><h1 id="Interrupted-Time-Series-Analysis"><a class="docs-heading-anchor" href="#Interrupted-Time-Series-Analysis">Interrupted Time Series Analysis</a><a id="Interrupted-Time-Series-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Interrupted-Time-Series-Analysis" title="Permalink"></a></h1><p>Sometimes we want to know how an outcome variable for a single unit changed after an event  or intervention. For example, if regulators announce sanctions against company A, we might  want to know how the price of stock A changed after the announcement. Since we do not know what the price of Company A&#39;s stock would have been if the santions were not announced, we need some way to predict those values. An interrupted time series analysis does this by  using some covariates that are related to the oucome variable but not related to whether the  event happened to predict what would have happened. The estimated effects are the  differences between the predicted post-event counterfactual outcomes and the observed  post-event outcomes, which can also be aggregated to mean or cumulative effects.  Estimating an interrupted time series design in CausalELM consists of three steps.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a deeper dive see:</p><pre><code class="nohighlight hljs">Bernal, James Lopez, Steven Cummins, and Antonio Gasparrini. &quot;Interrupted time series 
regression for the evaluation of public health interventions: a tutorial.&quot; International 
journal of epidemiology 46, no. 1 (2017): 348-355.</code></pre></div></div><h2 id="Step-1:-Initialize-an-interrupted-time-series-estimator"><a class="docs-heading-anchor" href="#Step-1:-Initialize-an-interrupted-time-series-estimator">Step 1: Initialize an interrupted time series estimator</a><a id="Step-1:-Initialize-an-interrupted-time-series-estimator-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Initialize-an-interrupted-time-series-estimator" title="Permalink"></a></h2><p>The InterruptedTimeSeries method takes at least four agruments: an array of pre-event  covariates, a vector of pre-event outcomes, an array of post-event covariates, and a vector  of post-event outcomes. </p><p>You can also specify whether or not to use L2 regularization, which activation function to  use, the metric to use when using cross validation to find the best number of neurons, the  minimum number of neurons to consider, the maximum number of neurons to consider, the number  of folds to use during cross caidation, the number of neurons to use in the ELM that learns  a mapping from number of neurons to validation loss, and whether to include a rolling  average autoregressive term. These options can be specified using the keyword arguments  regularized, activation, validation<em>metric, min</em>neurons, max<em>neurons, folds, iterations,  approximator</em>neurons, and autoregression.</p><pre><code class="language-julia hljs"># Generate some data to use
X₀, Y₀, X₁, Y₁ =  rand(1000, 5), rand(1000), rand(100, 5), rand(100)

# We could also use DataFrames
# using DataFrames
# X₀ = DataFrame(x1=rand(1000), x2=rand(1000), x3=rand(1000), x4=rand(1000), x5=rand(1000))
# X₁ = DataFrame(x1=rand(1000), x2=rand(1000), x3=rand(1000), x4=rand(1000), x5=rand(1000))
# Y₀, Y₁ = DataFrame(y=rand(1000)), DataFrame(y=rand(1000))

its = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)</code></pre><h2 id="Step-2:-Estimate-the-Treatment-Effect"><a class="docs-heading-anchor" href="#Step-2:-Estimate-the-Treatment-Effect">Step 2: Estimate the Treatment Effect</a><a id="Step-2:-Estimate-the-Treatment-Effect-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Estimate-the-Treatment-Effect" title="Permalink"></a></h2><p>Estimating the treatment effect only requires one argument: an InterruptedTimeSeries struct.</p><pre><code class="language-julia hljs">estimate_causal_effect!(its)</code></pre><h2 id="Step-3:-Get-a-Summary"><a class="docs-heading-anchor" href="#Step-3:-Get-a-Summary">Step 3: Get a Summary</a><a id="Step-3:-Get-a-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Get-a-Summary" title="Permalink"></a></h2><p>We can get a summary of the model, including a p-value and statndard via asymptotic  randomization inference, by pasing the model to the summarize method.</p><p>Calling the summarize methodd returns a dictionary with the estimator&#39;s task (always  regression for interrupted time series analysis), whether the model uses an L2 penalty,  the activation function used in the model&#39;s outcome predictors, the validation metric used  for cross validation to find the best number of neurons, the number of neurons used in the  ELMs used by the estimator, the number of neurons used in the ELM used to learn a mapping  from number of neurons to validation loss during cross validation, the causal effect,  standard error, and p-value.</p><pre><code class="language-julia hljs">summarize(its)</code></pre><h2 id="Step-4:-Validate-the-Model"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model">Step 4: Validate the Model</a><a id="Step-4:-Validate-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model" title="Permalink"></a></h2><p>For an interrupted time series design to work well we need to be able to get an unbiased  prediction of the counterfactual outcomes. If the event or intervention effected the  covariates we are using to predict the counterfactual outcomes, then we will not be able to  get unbiased predictions. We can verify this by conducting a Chow Test on the covariates. An ITS design also assumes that any observed effect is due to the hypothesized intervention,  rather than any simultaneous interventions, anticipation of the intervention, or any  intervention that ocurred after the hypothesized intervention. We can use a Wald supremum  test to see if the hypothesized intervention ocurred where there is the largest structural  break in the outcome or if there was a larger, statistically significant break in the  outcome that could confound an ITS analysis. The covariates in an ITS analysis should be  good predictors of the outcome. If this is the case, then adding irrelevant predictors  should not have much of a change on the results of the analysis. We can conduct all these  tests in one line of code.</p><p>One can also specify the number of simulated confounders to generate to test the sensitivity  of the model to confounding and the minimum and maximum proportion of data to use in the  Wald supremum test by including the n, low, and high keyword arguments.</p><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>Obtaining correct estimates is dependent on meeting the assumptions for interrupted time  series estimation. If the assumptions are not met then any estimates may be biased and  lead to incorrect conclusions.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a review of interrupted time series identifying assumptions and robustness checks, see:</p><pre><code class="nohighlight hljs">Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single 
interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.</code></pre></div></div><pre><code class="language-julia hljs">validate(its)</code></pre><h1 id="G-Computation"><a class="docs-heading-anchor" href="#G-Computation">G-Computation</a><a id="G-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#G-Computation" title="Permalink"></a></h1><p>In some cases, we may want to know the causal effect of a treatment that varies and is  confounded over time. For example, a doctor might want to know the effect of a treatment  given at multiple times whose status depends on the health of the patient at a given time.  One way to get an unbiased estimate of the causal effect is to use G-computation. The basic  steps for using G-computation in CausalELM are below.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a good overview of G-Computation see:</p><pre><code class="nohighlight hljs">Chatton, Arthur, Florent Le Borgne, Clémence Leyrat, Florence Gillaizeau, Chloé 
Rousseau, Laetitia Barbin, David Laplaud, Maxime Léger, Bruno Giraudeau, and Yohann 
Foucher. &quot;G-computation, propensity score-based methods, and targeted maximum likelihood 
estimator for causal inference with different covariates sets: a comparative simulation 
study.&quot; Scientific reports 10, no. 1 (2020): 9219.</code></pre></div></div><h2 id="Step-1:-Initialize-a-Model"><a class="docs-heading-anchor" href="#Step-1:-Initialize-a-Model">Step 1: Initialize a Model</a><a id="Step-1:-Initialize-a-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Initialize-a-Model" title="Permalink"></a></h2><p>The GComputation method takes at least three arguments: an array of covariates, a vector of  treatment statuses, and an outcome vector. </p><p>You can also specify the causal estimand, whether to employ L2 regularization, which  activation function to use, whether the data is of a temporal nature, the metric to use when  using cross validation to find the best number of neurons, the minimum number of neurons to  consider, the maximum number of neurons to consider, the number of folds to use during cross  caidation, and the number of neurons to use in the ELM that learns a mapping from number of  neurons to validation loss. These are options are specified with the following keyword  arguments: quantity<em>of</em>interest, regularized, activation, temporal, validation<em>metric,  min</em>neurons, max<em>neurons, folds, iterations, and approximator</em>neurons.</p><pre><code class="language-julia hljs"># Create some data with a binary treatment
X, T, Y =  rand(1000, 5), [rand()&lt;0.4 for i in 1:1000], rand(1000)

# We could also use DataFrames
# using DataFrames
# X = DataFrame(x1=rand(1000), x2=rand(1000), x3=rand(1000), x4=rand(1000), x5=rand(1000))
# T, Y = DataFrame(t=[rand()&lt;0.4 for i in 1:1000]), DataFrame(y=rand(1000))

g_computer = GComputation(X, T, Y)</code></pre><h2 id="Step-2:-Estimate-the-Causal-Effect"><a class="docs-heading-anchor" href="#Step-2:-Estimate-the-Causal-Effect">Step 2: Estimate the Causal Effect</a><a id="Step-2:-Estimate-the-Causal-Effect-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Estimate-the-Causal-Effect" title="Permalink"></a></h2><p>To estimate the causal effect, we pass the model above to estimatecausaleffect!.</p><pre><code class="language-julia hljs"># Note that we could also estimate the ATT by setting quantity_of_interest=&quot;ATT&quot;
estimate_causal_effect!(g_computer)</code></pre><h2 id="Step-3:-Get-a-Summary-2"><a class="docs-heading-anchor" href="#Step-3:-Get-a-Summary-2">Step 3: Get a Summary</a><a class="docs-heading-anchor-permalink" href="#Step-3:-Get-a-Summary-2" title="Permalink"></a></h2><p>We get a summary of the model that includes a p-value and standard error estimated via  asymptotic randomization inference by passing our model to the summarize method.</p><p>Calling the summarize methodd returns a dictionary with the estimator&#39;s task (regression or  classification), the quantity of interest being estimated (ATE or ATT), whether the model  uses an L2 penalty, the activation function used in the model&#39;s outcome predictors, whether  the data is temporal, the validation metric used for cross validation to find the best  number of neurons, the number of neurons used in the ELMs used by the estimator, the number  of neurons used in the ELM used to learn a mapping from number of neurons to validation  loss during cross validation, the causal effect, standard error, and p-value.</p><pre><code class="language-julia hljs">summarize(g_computer)</code></pre><h2 id="Step-4:-Validate-the-Model-2"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model-2">Step 4: Validate the Model</a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model-2" title="Permalink"></a></h2><p>We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model&#39;s  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  probability of treatment. If the matrix is empty, none of the observations have an estimated  zero probability of treatment, which implies the positivity assumption is satisfied.</p><p>One can also specify the maxium number of possible treatments to consider for the causal  consistency assumption and the minimum and maximum probabilities of treatment for the  positivity assumption with the num_treatments, min, and max keyword arguments.</p><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>Obtaining correct estimates is dependent on meeting the assumptions for G-computation.  If the assumptions are not met then any estimates may be biased and lead to incorrect  conclusions.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a thorough review of casual inference assumptions see:</p><pre><code class="nohighlight hljs">Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and 
Francis, 2024.</code></pre><p>For more information on the E-value test see:</p><pre><code class="nohighlight hljs">VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research: 
introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</code></pre></div></div><pre><code class="language-julia hljs">validate(g_computer)</code></pre><h1 id="Double-Machine-Learning"><a class="docs-heading-anchor" href="#Double-Machine-Learning">Double Machine Learning</a><a id="Double-Machine-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Double-Machine-Learning" title="Permalink"></a></h1><p>Double machine learning, also called debiased or orthogonalized machine learning, enables estimating causal effects when the dimensionality of the covariates is too high for linear  regression or the model does not assume a parametric form. In other words, when the  relathionship between the treatment or covariates and outcome is nonlinear and we do not  know the functional form. </p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For more information see:</p><p>Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen,  Whitney Newey, and James Robins. &quot;Double/debiased machine learning for treatment and  structural parameters.&quot; (2018): C1-C68.</p></div></div><h2 id="-Step-1:-Initialize-a-Model"><a class="docs-heading-anchor" href="##-Step-1:-Initialize-a-Model"># Step 1: Initialize a Model</a><a id="-Step-1:-Initialize-a-Model-1"></a><a class="docs-heading-anchor-permalink" href="##-Step-1:-Initialize-a-Model" title="Permalink"></a></h2><p>The DoubleMachineLearning constructor takes at least three arguments, an array of  covariates, a treatment vector, and an outcome vector. </p><p>You can also specify the following options: whether the treatment vector is categorical ie  not continuous and containing more than two classes, whether to use L2 regularization, the  activation function, the validation metric to use when searching for the best number of  neurons, the minimum and maximum number of neurons to consider, the number of folds to use  for cross validation, the number of iterations to perform cross validation, and the number  of neurons to use in the ELM used to learn the function from number of neurons to validation  loss. These arguments are specified with the following keyword arguments: t<em>cat,  regularized, activation, validation</em>metric, min<em>neurons, max</em>neurons, folds, iterations, and  approximator_neurons.</p><pre><code class="language-julia hljs"># Create some data with a binary treatment
X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)

# We could also use DataFrames
# using DataFrames
# X = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100), x5=rand(100))
# T, Y = DataFrame(t=[rand()&lt;0.4 for i in 1:100]), DataFrame(y=rand(100))

dml = DoubleMachineLearning(X, T, Y)</code></pre><h2 id="Step-2:-Estimate-the-Causal-Effect-2"><a class="docs-heading-anchor" href="#Step-2:-Estimate-the-Causal-Effect-2">Step 2: Estimate the Causal Effect</a><a class="docs-heading-anchor-permalink" href="#Step-2:-Estimate-the-Causal-Effect-2" title="Permalink"></a></h2><p>To estimate the causal effect, we call estimatecausaleffect! on the model above.</p><pre><code class="language-julia hljs"># we could also estimate the ATT by passing quantity_of_interest=&quot;ATT&quot;
estimate_causal_effect!(dml)</code></pre><h1 id="Get-a-Summary"><a class="docs-heading-anchor" href="#Get-a-Summary">Get a Summary</a><a id="Get-a-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Get-a-Summary" title="Permalink"></a></h1><p>We can get a summary that includes a p-value and standard error estimated via asymptotic  randomization inference by passing our model to the summarize method.</p><p>Calling the summarize methodd returns a dictionary with the estimator&#39;s task (regression or  classification), the quantity of interest being estimated (ATE), whether the model uses an  L2 penalty (always true for DML), the activation function used in the model&#39;s outcome  predictors, whether the data is temporal (always false for DML), the validation metric used  for cross validation to find the best number of neurons, the number of neurons used in the  ELMs used by the estimator, the number of neurons used in the ELM used to learn a mapping  from number of neurons to validation loss during cross validation, the causal effect,  standard error, and p-value.</p><pre><code class="language-julia hljs"># Can also use the British spelling
# summarise(dml)

summarize(dml)</code></pre><h2 id="Step-4:-Validate-the-Model-3"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model-3">Step 4: Validate the Model</a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model-3" title="Permalink"></a></h2><p>We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model&#39;s  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  or near zero probability of treatment. If the matrix is empty, none of the observations have  an estimated zero probability of treatment, which implies the positivity assumption is  satisfied.</p><p>One can also specify the maxium number of possible treatments to consider for the causal  consistency assumption and the minimum and maximum probabilities of treatment for the  positivity assumption with the num_treatments, min, and max keyword arguments.</p><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>Obtaining correct estimates is dependent on meeting the assumptions for double machine  learning. If the assumptions are not met then any estimates may be biased and lead to  incorrect conclusions.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a thorough review of casual inference assumptions see:</p><pre><code class="nohighlight hljs">Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and 
Francis, 2024.</code></pre><p>For more information on the E-value test see:</p><pre><code class="nohighlight hljs">VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research: 
introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</code></pre></div></div><pre><code class="language-julia hljs">validate(g_computer)</code></pre><h1 id="Metalearners"><a class="docs-heading-anchor" href="#Metalearners">Metalearners</a><a id="Metalearners-1"></a><a class="docs-heading-anchor-permalink" href="#Metalearners" title="Permalink"></a></h1><p>Instead of knowing the average cuasal effect, we might want to know which units benefit and  which units lose by being exposed to a treatment. For example, a cash transfer program might  motivate some people to work harder and incentivize others to work less. Thus, we might want  to know how the cash transfer program affects individuals instead of it average affect on  the population. To do so, we can use metalearners. Depending on the scenario, we may want to  use an S-learner, a T-learner, an X-learner, or an R-learner. The basic steps to use all  three metalearners are below. The difference between the metalearners is how they estimate  the CATE and what types of variables they can handle. In the case of S, T, and X learners,  they can only handle binary treatments. On the other hand, R-learners can handle binary,  categorical, count, or continuous treatments but only supports continuous outcomes.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a deeper dive on S-learning, T-learning, and X-learning see:</p><pre><code class="nohighlight hljs">Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for 
estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of the 
national academy of sciences 116, no. 10 (2019): 4156-4165.</code></pre><p>To learn more about R-learning see:</p><pre><code class="nohighlight hljs">Nie, Xinkun, and Stefan Wager. &quot;Quasi-oracle estimation of heterogeneous treatment 
effects.&quot; Biometrika 108, no. 2 (2021): 299-319.</code></pre></div></div><h1 id="Initialize-a-Metalearner"><a class="docs-heading-anchor" href="#Initialize-a-Metalearner">Initialize a Metalearner</a><a id="Initialize-a-Metalearner-1"></a><a class="docs-heading-anchor-permalink" href="#Initialize-a-Metalearner" title="Permalink"></a></h1><p>S-learners, T-learners, and X-learners all take at least three arguments: an array of  covariates, a vector of outcomes, and a vector of treatment statuses. Additional options can  be specified for each type of metalearner using its keyword arguments.</p><pre><code class="language-julia hljs"># Generate data to use
X, Y, T =  rand(1000, 5), rand(1000), [rand()&lt;0.4 for i in 1:1000]

# We could also use DataFrames
# using DataFrames
# X = DataFrame(x1=rand(1000), x2=rand(1000), x3=rand(1000), x4=rand(1000), x5=rand(1000))
# T, Y = DataFrame(t=[rand()&lt;0.4 for i in 1:1000]), DataFrame(y=rand(1000))

s_learner = SLearner(X, Y, T)
t_learner = TLearner(X, Y, T)
x_learner = XLearner(X, Y, T)
r_learner = RLearner(X, Y, T)</code></pre><h1 id="Estimate-the-CATE"><a class="docs-heading-anchor" href="#Estimate-the-CATE">Estimate the CATE</a><a id="Estimate-the-CATE-1"></a><a class="docs-heading-anchor-permalink" href="#Estimate-the-CATE" title="Permalink"></a></h1><p>We can estimate the CATE for all the models by passing them to estimate<em>causal</em>effect!.</p><pre><code class="language-julia hljs">estimate_causal_effect!(s_learner)
estimate_causal_effect!(t_learner)
estimate_causal_effect!(x_learner)
estimate_causal_effect!(r_learner)</code></pre><h1 id="Get-a-Summary-2"><a class="docs-heading-anchor" href="#Get-a-Summary-2">Get a Summary</a><a class="docs-heading-anchor-permalink" href="#Get-a-Summary-2" title="Permalink"></a></h1><p>We can get a summary of the models that includes p0values and standard errors for the  average treatment effect by passing the models to the summarize method.</p><p>Calling the summarize methodd returns a dictionary with the estimator&#39;s task (regression or  classification), the quantity of interest being estimated (CATE), whether the model  uses an L2 penalty, the activation function used in the model&#39;s outcome predictors, whether  the data is temporal, the validation metric used for cross validation to find the best  number of neurons, the number of neurons used in the ELMs used by the estimator, the number  of neurons used in the ELM used to learn a mapping from number of neurons to validation  loss during cross validation, the causal effect, standard error, and p-value for the ATE.</p><pre><code class="language-julia hljs">summarize(s_learner)
summarize(t_learner)
summarize(x_learner)
summarize(r_learner)</code></pre><h2 id="Step-4:-Validate-the-Model-4"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model-4">Step 4: Validate the Model</a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model-4" title="Permalink"></a></h2><p>We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model&#39;s  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  probability of treatment. If the matrix is empty, none of the observations have an estimated  zero probability of treatment, which implies the positivity assumption is satisfied.</p><p>One can also specify the maxium number of possible treatments to consider for the causal  consistency assumption and the minimum and maximum probabilities of treatment for the  positivity assumption with the num_treatments, min, and max keyword arguments.</p><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>Obtaining correct estimates is dependent on meeting the assumptions for interrupted time  series estimation. If the assumptions are not met then any estimates may be biased and  lead to incorrect conclusions.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a thorough review of casual inference assumptions see:</p><pre><code class="nohighlight hljs">Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and 
Francis, 2024.</code></pre><p>For more information on the E-value test see:</p><pre><code class="nohighlight hljs">VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research: 
introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</code></pre></div></div><pre><code class="language-julia hljs">validate(s_learner)
validate(t_learner)
validate(x_learner)
validate(r_learner)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« causalELM</a><a class="docs-footer-nextpage" href="../api/">API »</a><div class="flexbox-break"></div><p class="footer-message">© 2024 Darren Colby</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 15 January 2024 21:55">Monday 15 January 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
