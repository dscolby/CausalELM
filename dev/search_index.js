var documenterSearchIndex = {"docs":
[{"location":"guide/gcomputation/#G-Computation","page":"G-computation","title":"G-Computation","text":"","category":"section"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"In some cases, we may want to know the causal effect of a treatment that varies and is  confounded over time. For example, a doctor might want to know the effect of a treatment  given at multiple times whose status depends on the health of the patient at a given time.  One way to get an unbiased estimate of the causal effect is to use G-computation. The basic  steps for using G-computation in CausalELM are below.","category":"page"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"For a good overview of G-Computation see:     Chatton, Arthur, Florent Le Borgne, Clémence Leyrat, Florence Gillaizeau, Chloé      Rousseau, Laetitia Barbin, David Laplaud, Maxime Léger, Bruno Giraudeau, and Yohann      Foucher. \"G-computation, propensity score-based methods, and targeted maximum likelihood      estimator for causal inference with different covariates sets: a comparative simulation      study.\" Scientific reports 10, no. 1 (2020): 9219.","category":"page"},{"location":"guide/gcomputation/#Step-1:-Initialize-a-Model","page":"G-computation","title":"Step 1: Initialize a Model","text":"","category":"section"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"The GComputation method takes three arguments: an array of covariates, a vector of  outcomes, and a vector of treatment statuses.","category":"page"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"# Create some data with a binary treatment\nX, Y, T =  rand(1000, 5), rand(1000), [rand()<0.4 for i in 1:1000]\n\ng_computer = GComputation(X, Y, T)","category":"page"},{"location":"guide/gcomputation/#Step-2:-Estimate-the-Causal-Effect","page":"G-computation","title":"Step 2: Estimate the Causal Effect","text":"","category":"section"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"To estimate the causal effect, we pass the model above to estimatecausaleffect!.","category":"page"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"# Note that we could also estimate the ATT by setting quantity_of_interest=\"ATT\"\nestimate_causal_effect!(g_computer)","category":"page"},{"location":"guide/gcomputation/#Step-3:-Get-a-Summary","page":"G-computation","title":"Step 3: Get a Summary","text":"","category":"section"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"We get a summary of the model that includes a p-value and standard error estimated via  asymptotic randomization inference by passing our model to the summarize method.","category":"page"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"summarize(g_computer)","category":"page"},{"location":"guide/gcomputation/#Step-4:-Validate-the-Model","page":"G-computation","title":"Step 4: Validate the Model","text":"","category":"section"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model's  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  probability of treatment. If the matrix is empty, none of the observations have an estimated  zero probability of treatment, which implies the positivity assumption is satisfied.","category":"page"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"For a thorough review of casual inference assumptions see:     Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and      Francis, 2024. ","category":"page"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"For more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. \"Sensitivity analysis in observational research:      introducing the E-value.\" Annals of internal medicine 167, no. 4 (2017): 268-274.","category":"page"},{"location":"guide/gcomputation/","page":"G-computation","title":"G-computation","text":"validate(g_computer)","category":"page"},{"location":"contributing/#Contributing","page":"Contributing","title":"Contributing","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"All contributions are welcome. To ensure contributions align with the existing code base and  are not duplicated, please follow the guidelines below.","category":"page"},{"location":"contributing/#Reporting-a-Bug","page":"Contributing","title":"Reporting a Bug","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"To report a bug, open an issue on the CausalELM.jl GitHub page. Please include all relevant  information, such as what methods were called, the operating system used, the verion/s of  CausalELM used, the verion/s of Julia used, any tracebacks or error codes, and any other  information that would be helpful for debugging.","category":"page"},{"location":"contributing/#Requesting-New-Features","page":"Contributing","title":"Requesting New Features","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Before requesting a new feature, please check the issues page on GitHub to make sure someone else did not already request the same feature. If this is not the case, then please open an issue that explains what function or method you would like to be added and how you believe  it should behave.","category":"page"},{"location":"contributing/#Contributing-Code","page":"Contributing","title":"Contributing Code","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Before submitting a pull request, please open an issue explaining what the proposed code is and why you want to add it. When submitting a pull request, please reference the relevant issue/s. Please also ensure your code follows the guidelines below.","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"All abstract structs, structs, functions, methods, macros, and constants have docstrings    that follow the same format as the other docstrings. These functions should also be    included in the relevant section of the API Manual.\nThere are no repeated code blocks. If there are repeated codeblocks, then they should be    in a separate function.\nMethods should generally include types and be type stable. If there is a strong reason    to deviate from this point, there should be a comment in the code explaining why.\nMinimize use of new constants and macros. If they must be included, the reason for their    inclusion should be obvious or included in the docstring.\nAvoid using global variables and constants.\nCode should take advantage of Julia's macros for performance. Use @inbounds, @view,    @fastmath, and @simd when possible.\nWhen appending to an array in a loop, preallocate the array and update its values by    index.\nAvoid long functions and decompose them into smaller functions or methods.\nUse self-explanatory names for variables, methods, structs, constants, and macros.","category":"page"},{"location":"reference/crossval/#Cross-Valdiation","page":"Cross Validation","title":"Cross Valdiation","text":"","category":"section"},{"location":"reference/crossval/","page":"Cross Validation","title":"Cross Validation","text":"Methods to find the optimal number of neurons via cross validation","category":"page"},{"location":"reference/crossval/","page":"Cross Validation","title":"Cross Validation","text":"CausalELM.CrossValidation\nCausalELM.CrossValidation.recode\nCausalELM.CrossValidation.generate_folds\nCausalELM.CrossValidation.validate_fold\nCausalELM.CrossValidation.cross_validate\nCausalELM.CrossValidation.best_size\nCausalELM.CrossValidation.shuffle_data","category":"page"},{"location":"reference/crossval/#CausalELM.CrossValidation","page":"Cross Validation","title":"CausalELM.CrossValidation","text":"Methods to perform cross validation and find the optimum number of neurons.\n\nTo reduce computation time, the number of neurons is optimized by using cross validation to estimate the validation error on a small subset of the range of possible numbers of  neurons. Then, an Extreme Learning Machine is trained to predict validation loss from  the given cross validation sets. Finally, the number of neurons is selected that has the  smallest predicted loss or the highest classification metric.\n\n\n\n\n\n","category":"module"},{"location":"reference/crossval/#CausalELM.CrossValidation.recode","page":"Cross Validation","title":"CausalELM.CrossValidation.recode","text":"recode(ŷ)\n\nRound predicted values to their predicted class for classification tasks.\n\nIf the smallest predicted label is 0, all labels are shifted up 1; if the smallest  label is -1, all labels are shifted up 2. Also labels cannot be smaller than -1.\n\nExamples\n\njulia> recode([-0.7, 0.2, 1.1])\n3-element Vector{Float64}\n1\n2\n3\njulia> recode([0.1, 0.2, 0.3])\n3-element Vector{Float64}\n1\n1\n1\njulia> recode([1.1, 1.51, 1.8])\n3-element Vector{Float64}\n1\n2\n2\n\n\n\n\n\n","category":"function"},{"location":"reference/crossval/#CausalELM.CrossValidation.generate_folds","page":"Cross Validation","title":"CausalELM.CrossValidation.generate_folds","text":"generate_folds(X, Y, folds)\n\nCreates folds for cross validation.\n\nExamples\n\njulia> xfolds, y_folds = generate_folds(zeros(20, 2), zeros(20), 5)\n\n\n\n\n\n","category":"function"},{"location":"reference/crossval/#CausalELM.CrossValidation.cross_validate","page":"Cross Validation","title":"CausalELM.CrossValidation.cross_validate","text":"cross_validate(X, Y, neurons, metric, activation, regularized, folds, temporal)\n\nCalculate a validation metric for k folds using a single set of hyperparameters.\n\nExamples\n\njulia> x = rand(100, 5); y = Float64.(rand(100) .> 0.5)\njulia> cross_validate(x, y, 5, accuracy)\n0.0257841765251021\n\n\n\n\n\n","category":"function"},{"location":"reference/crossval/#CausalELM.CrossValidation.best_size","page":"Cross Validation","title":"CausalELM.CrossValidation.best_size","text":"best_size(X, Y, metric, task, activation, min_neurons, max_neurons, regularized, folds, \n    temporal, iterations, elm_size)\n\nCompute the best number of neurons for an Extreme Learning Machine.\n\nThe procedure tests networks with numbers of neurons in a sequence whose length is given  by iterations on the interval [minneurons, maxneurons]. Then, it uses the networks  sizes and validation errors from the sequence to predict the validation error or metric  for every network size between minneurons and maxneurons using the function  approximation ability of an Extreme Learning Machine. Finally, it returns the network  size with the best predicted validation error or metric.\n\nExamples\n\njulia> best_size(rand(100, 5), rand(100), mse, \"regression\")\n11\n\n\n\n\n\n","category":"function"},{"location":"reference/crossval/#CausalELM.CrossValidation.shuffle_data","page":"Cross Validation","title":"CausalELM.CrossValidation.shuffle_data","text":"shuffle_data(X, Y, T)\n\nShuffles covariates, treatment vector, and outcome vector for cross validation.\n\nExamples\n\njulia> x, y, t = rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> shuffle_data(x, y, t)\n([0.6124923085225416 0.2713900065807924 … 0.6094796972512194 0.6067966603192685; \n0.7186612932571539 0.8047878363606299 … 0.9787878554455594 0.885819212905816; … ; \n0.773543733306263 0.10880091279797399 … 0.10525512055751185 0.6303472234021711; \n0.10845217539341823 0.9911071602976902 … 0.014754069216096566 0.5256103389041187], \n[0.4302689295553531, 0.2396683446618325, 0.7954433314513768, 0.7191098533903124, \n0.8168563428651753, 0.7064320936729905, 0.048113106979693065, 0.3102938851371281, \n0.6246380539228858, 0.3510284321966193  …  0.5324022501182528, 0.8354720951777901, \n0.7526652774981095, 0.3639742621882005, 0.21030903031988923, 0.6936212944871928, \n0.3910592143534404, 0.15152013651215301, 0.38891692138831735, 0.08827711410802941], \nFloat64[0, 0, 1, 1, 0, 1, 0, 0, 1, 0  …  0, 0, 1, 1, 1, 1, 0, 1, 0, 0])\n\n\n\n\n\n","category":"function"},{"location":"reference/metrics/#Validation-Metrics","page":"Validation Metrics","title":"Validation Metrics","text":"","category":"section"},{"location":"reference/metrics/","page":"Validation Metrics","title":"Validation Metrics","text":"Validation metrics used in cross validation of CausalELM estimators","category":"page"},{"location":"reference/metrics/","page":"Validation Metrics","title":"Validation Metrics","text":"CausalELM.Metrics\nCausalELM.Metrics.mse\nCausalELM.Metrics.mae\nCausalELM.Metrics.confusion_matrix\nCausalELM.Metrics.accuracy\nCausalELM.Metrics.precision\nCausalELM.Metrics.recall\nCausalELM.Metrics.F1","category":"page"},{"location":"reference/metrics/#CausalELM.Metrics","page":"Validation Metrics","title":"CausalELM.Metrics","text":"Metrics to evaluate the performance of an Extreme learning machine for regression and classification tasks.\n\n\n\n\n\n","category":"module"},{"location":"reference/metrics/#CausalELM.Metrics.mse","page":"Validation Metrics","title":"CausalELM.Metrics.mse","text":"mse(y, ŷ)\n\nCalculate the mean squared error\n\nSee also mae.\n\nExamples\n\njulia> mse([0.0, 0.0, 0.0], [0.0, 0.0, 0.0])\n0\njulia> mse([-1.0, -1.0, -1.0], [1.0, 1.0, 1.0])\n4\n\n\n\n\n\n","category":"function"},{"location":"reference/metrics/#CausalELM.Metrics.mae","page":"Validation Metrics","title":"CausalELM.Metrics.mae","text":"mae(y, ŷ)\n\nCalculate the mean absolute error\n\nSee also mse.\n\nExamples\n\njulia> mae([-1.0, -1.0, -1.0], [1.0, 1.0, 1.0])\n2\njulia> mae([1.0, 1.0, 1.0], [2.0, 2.0, 2.0])\n1\n\n\n\n\n\n","category":"function"},{"location":"reference/metrics/#CausalELM.Metrics.confusion_matrix","page":"Validation Metrics","title":"CausalELM.Metrics.confusion_matrix","text":"confusion_matrix(y, ŷ)\n\nGenerate a confusion matrix\n\nExamples\n\njulia> confusion_matrix([1, 1, 1, 1, 0], [1, 1, 1, 1, 0])\n2×2 Matrix{Int64}:\n 1  0\n 0 4\njulia> confusion_matrix([1, 1, 1, 1, 0, 2], [1, 1, 1, 1, 0, 2])\n3×3 Matrix{Int64}:\n 1  0 0\n 0 4 0\n 0 0 1\n\n\n\n\n\n","category":"function"},{"location":"reference/metrics/#CausalELM.Metrics.accuracy","page":"Validation Metrics","title":"CausalELM.Metrics.accuracy","text":"accuracy(y, ŷ)\n\nCalculate the accuracy for a classification task\n\nExamples\n\njulia> accuracy([1, 1, 1, 1], [0, 1, 1, 0])\n0.5\njulia> accuracy([1, 2, 3, 4], [1, 1, 1, 1])\n0.25\n\n\n\n\n\n","category":"function"},{"location":"reference/metrics/#CausalELM.Metrics.precision","page":"Validation Metrics","title":"CausalELM.Metrics.precision","text":"precision(y, ŷ)\n\nCalculate the precision for a classification task\n\nSee also recall.\n\nExamples\n\njulia> precision([0, 1, 0, 0], [0, 1, 1, 0])\n0.5\njulia> precision([0, 1, 0, 0], [0, 1, 0, 0])\n1\n\n\n\n\n\n","category":"function"},{"location":"reference/metrics/#CausalELM.Metrics.recall","page":"Validation Metrics","title":"CausalELM.Metrics.recall","text":"recall(y, ŷ)\n\nCalculate the recall for a classification task\n\nSee also precision.\n\nExamples\n\njulia> recall([1, 2, 1, 3, 0], [2, 2, 2, 3, 1])\n0.5\njulia> recall([1, 2, 1, 3, 2], [2, 2, 2, 3, 1])\n1\n\n\n\n\n\n","category":"function"},{"location":"reference/metrics/#CausalELM.Metrics.F1","page":"Validation Metrics","title":"CausalELM.Metrics.F1","text":"F1(y, ŷ)\n\nCalculate the F1 score for a classification task\n\nExamples\n\njulia> F1([1, 2, 1, 3, 0], [2, 2, 2, 3, 1])\n0.4\njulia> F1([1, 2, 1, 3, 2], [2, 2, 2, 3, 1])\n0.47058823529411764\n\n\n\n\n\n","category":"function"},{"location":"reference/metalearners/#CATE-Estimation","page":"CATE Estimation","title":"CATE Estimation","text":"","category":"section"},{"location":"reference/metalearners/","page":"CATE Estimation","title":"CATE Estimation","text":"Stucts and methods to estimate the CATE from observational data","category":"page"},{"location":"reference/metalearners/","page":"CATE Estimation","title":"CATE Estimation","text":"CausalELM.Metalearners\nCausalELM.Metalearners.Metalearner\nCausalELM.Metalearners.SLearner\nCausalELM.Metalearners.TLearner\nCausalELM.Metalearners.XLearner\nCausalELM.Metalearners.estimate_causal_effect!\nCausalELM.Metalearners.stage1!\nCausalELM.Metalearners.stage2!","category":"page"},{"location":"reference/metalearners/#CausalELM.Metalearners","page":"CATE Estimation","title":"CausalELM.Metalearners","text":"Metalearners to estimate the conditional average treatment effect (CATE).\n\n\n\n\n\n","category":"module"},{"location":"reference/metalearners/#CausalELM.Metalearners.Metalearner","page":"CATE Estimation","title":"CausalELM.Metalearners.Metalearner","text":"Abstract type for metalearners\n\n\n\n\n\n","category":"type"},{"location":"reference/metalearners/#CausalELM.Metalearners.SLearner","page":"CATE Estimation","title":"CausalELM.Metalearners.SLearner","text":"S-Learner for CATE estimation.\n\n\n\n\n\n","category":"type"},{"location":"reference/metalearners/#CausalELM.Metalearners.TLearner","page":"CATE Estimation","title":"CausalELM.Metalearners.TLearner","text":"T-Learner for CATE estimation.\n\n\n\n\n\n","category":"type"},{"location":"reference/metalearners/#CausalELM.Metalearners.XLearner","page":"CATE Estimation","title":"CausalELM.Metalearners.XLearner","text":"X-Learner for CATE estimation.\n\n\n\n\n\n","category":"type"},{"location":"reference/metalearners/#CausalELM.Metalearners.stage1!","page":"CATE Estimation","title":"CausalELM.Metalearners.stage1!","text":"stage1!(x)\n\nEstimate the first stage models for an X-learner.\n\nThis method should not be called by the user.\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m1 = XLearner(X, Y, T)\njulia> stage1!(m1)\n\n\n\n\n\n","category":"function"},{"location":"reference/metalearners/#CausalELM.Metalearners.stage2!","page":"CATE Estimation","title":"CausalELM.Metalearners.stage2!","text":"stage2!(x)\n\nEstimate the second stage models for an X-learner.\n\nThis method should not be called by the user.\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m1 = XLearner(X, Y, T)\njulia> stage1!(m1)\njulia> stage2!(m1)\n\n\n\n\n\n","category":"function"},{"location":"reference/inference/#Inference-and-Summarization","page":"Inference and Summarization","title":"Inference and Summarization","text":"","category":"section"},{"location":"reference/inference/","page":"Inference and Summarization","title":"Inference and Summarization","text":"Methods for summarization and inference of estimators in the CausalELM package","category":"page"},{"location":"reference/inference/","page":"Inference and Summarization","title":"Inference and Summarization","text":"CausalELM.Inference\nCausalELM.Inference.summarize\nCausalELM.Inference.quantities_of_interest\nCausalELM.Inference.generate_null_distribution","category":"page"},{"location":"reference/inference/#CausalELM.Inference","page":"Inference and Summarization","title":"CausalELM.Inference","text":"Methods for summarization and inference from estimators and metalearners.\n\n\n\n\n\n","category":"module"},{"location":"reference/inference/#CausalELM.summarize","page":"Inference and Summarization","title":"CausalELM.summarize","text":"summarize(its, mean_effect)\n\nReturn a summary from an interrupted time series estimator.\n\np-values and standard errors are estimated using approximate randomization inference that permutes the time of the intervention.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> X₀, Y₀, X₁, Y₁ =  rand(100, 5), rand(100), rand(10, 5), rand(10)\njulia> m1 = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)\njulia> estimatetreatmenteffect!(m1)\n[0.25714308]\njulia> summarize(m1)\n{\"Task\" => \"Regression\", \"Regularized\" => true, \"Activation Function\" => relu, \n\"Validation Metric\" => \"mse\",\"Number of Neurons\" => 2, \n\"Number of Neurons in Approximator\" => 10, \"β\" => [0.25714308], \n\"Causal Effect\" => -3.9101138, \"Standard Error\" => 1.903434356, \"p-value\" = 0.00123356}\n\n\n\n\n\nsummarize(g)\n\nReturn a summary from a G-Computation estimator.\n\np-values and standard errors are estimated using approximate randomization inference.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m1 = GComputation(X, Y, T)\njulia> estimate_causal_effect!(m1)\n[0.3100468253]\njulia> summarize(m1)\n{\"Task\" => \"Regression\", \"Quantity of Interest\" => \"ATE\", Regularized\" => \"true\", \n\"Activation Function\" => \"relu\", \"Time Series/Panel Data\" => \"false\", \n\"Validation Metric\" => \"mse\",\"Number of Neurons\" => \"5\", \n\"Number of Neurons in Approximator\" => \"10\", \"β\" => \"[0.3100468253]\",\n\"Causal Effect: 0.00589761, \"Standard Error\" => 5.12900734, \"p-value\" => 0.479011245} \n\n\n\n\n\nsummarize(dml, n)\n\nReturn a summary from a doubly robust estimator.\n\np-values and standard errors are estimated using approximate randomization inference.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m1 = DoubleMachineLearning(X, X, Y, T)\njulia> estimate_causal_effect(m1)\n[0.5804032956]\njulia> summarize(m1)\n{\"Task\" => \"Regression\", \"Quantity of Interest\" => \"ATE\", Regularized\" => \"true\", \n\"Activation Function\" => \"relu\", \"Validation Metric\" => \"mse\", \"Number of Neurons\" => \"5\", \n\"Number of Neurons in Approximator\" => \"10\", \"Causal Effect\" = 0.5804032956, \n\"Standard Error\" => 2.129400324, \"p-value\" => 0.0008342356}\n\n\n\n\n\nsummarize(m, n)\n\nReturn a summary from a metalearner.\n\nExamples\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m1 = SLearner(X, Y, T)\njulia> estimate_causal_effect!(m1)\n[0.20729633391630697, 0.20729633391630697, 0.20729633391630692, 0.20729633391630697, \n0.20729633391630697, 0.20729633391630697, 0.20729633391630697, 0.20729633391630703, \n0.20729633391630697, 0.20729633391630697  …  0.20729633391630703, 0.20729633391630697, \n0.20729633391630692, 0.20729633391630703, 0.20729633391630697, 0.20729633391630697, \n0.20729633391630692, 0.20729633391630697, 0.20729633391630697, 0.20729633391630697]\njulia> summarise(m1)\n{\"Task\" => \"Regression\", Regularized\" => \"true\", \"Activation Function\" => \"relu\", \n\"Validation Metric\" => \"mse\", \"Number of Neurons\" => \"5\", \n\"Number of Neurons in Approximator\" => \"10\", \n\"β\" => \"[0.3100468253]\", \"Causal Effect: [0.20729633391630697, 0.20729633391630697, \n0.20729633391630692, 0.20729633391630697, 0.20729633391630697, 0.20729633391630697, \n0.20729633391630697, 0.20729633391630703, 0.20729633391630697, 0.20729633391630697  …  \n0.20729633391630703, 0.20729633391630697, 0.20729633391630692, 0.20729633391630703, \n0.20729633391630697, 0.20729633391630697, 0.20729633391630692, 0.20729633391630697, \n0.20729633391630697, 0.20729633391630697], \"Standard Error\" => 5.3121435085, \n\"p-value\" => 0.0632454855}\n\n\n\n\n\n","category":"function"},{"location":"reference/inference/#CausalELM.Inference.quantities_of_interest","page":"Inference and Summarization","title":"CausalELM.Inference.quantities_of_interest","text":"quantities_of_interest(model, n)\n\nGenerate a p-value and standard error through randomization inference\n\nThis method generates a null distribution of treatment effects by reestimating treatment  effects from permutations of the treatment vector and estimates a p-value and standard from the generated distribution.\n\nNote that lowering the number of iterations increases the probability of failing to reject the null hypothesis.\n\nFor a primer on randomization inference see:     https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> x, y, t = rand(100, 5), rand(1:100, 100, 1), [rand()<0.4 for i in 1:100]\njulia> g_computer = GComputation(x, y, t)\njulia> estimate_causal_effect!(g_computer)\njulia> quantities_of_interest(g_computer, 1000)\n(0.114, 6.953133617011371)\n\n\n\n\n\nquantities_of_interest(model, n)\n\nGenerate a p-value and standard error through randomization inference\n\nThis method generates a null distribution of treatment effects by reestimating treatment  effects from permutations of the treatment vector and estimates a p-value and standard from  the generated distribution. Randomization for event studies is done by creating time splits  at even intervals and reestimating the causal effect.\n\nNote that lowering the number of iterations increases the probability of failing to reject the null hypothesis.\n\nFor a primer on randomization inference see:     https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> x₀, y₀, x₁, y₁ = rand(1:100, 100, 5), rand(100), rand(10, 5), rand(10)\njulia> its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)\njulia> estimate_causal_effect!(its)\njulia> quantities_of_interest(its, 10)\n(0.0, 0.07703275541001667)\n\n\n\n\n\n","category":"function"},{"location":"reference/inference/#CausalELM.Inference.generate_null_distribution","page":"Inference and Summarization","title":"CausalELM.Inference.generate_null_distribution","text":"generate_null_distribution(e, n)\n\nGenerate a null distribution for the treatment effect of G-computation, doubly robust  estimation, or metalearning.\n\nThis method estimates the same model that is provided using random permutations of the  treatment assignment to generate a vector of estimated effects under different treatment regimes. When e is a metalearner the null statistic is the difference is the ATE.\n\nNote that lowering the number of iterations increases the probability of failing to reject the null hypothesis.\n\nExamples\n\njulia> x, y, t = rand(100, 5), rand(1:100, 100, 1), [rand()<0.4 for i in 1:100]\njulia> g_computer = GComputation(x, y, t)\njulia> estimate_causal_effect!(g_computer)\njulia> generate_null_distribution(g_computer, 500)\n[0.016297180690693656, 0.0635928694685571, 0.20004144093635673, 0.505893866040335, \n0.5130594630907543, 0.5432486130493388, 0.6181727442724846, 0.61838399963459, \n0.7038981488009489, 0.7043407710415689  …  21.909186142780246, 21.960498059428854, \n21.988553083790023, 22.285403459215363, 22.613625375395973, 23.382102081355548, \n23.52056245175936, 24.739658523175912, 25.30523686137909, 28.07474553316176]\n\n\n\n\n\ngenerate_null_distribution(its, n, mean_effect)\n\nGenerate a null distribution for the treatment effect in an interrupted time series  analysis. By default, this method generates a null distribution of mean differences. To  generate a null distribution of cummulative differences, set the mean_effect argument to  false.\n\nRandomization is conducted by randomly assigning observations to the pre and  post-intervention periods, resestimating the causal effect, and repeating n times. The null  distribution is the set of n casual effect estimates.\n\nNote that lowering the number of iterations increases the probability of failing to reject the null hypothesis.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> x₀, y₀, x₁, y₁ = rand(1:100, 100, 5), rand(100), rand(10, 5), rand(10)\njulia> its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)\njulia> estimate_causale_ffect!(its)\njulia> generate_null_distribution(its, 10)\n[-0.5012456678829079, -0.33790650529972194, -0.2534340182760628, -0.21030239864895905, \n-0.11672915615117885, -0.08149441936166794, -0.0685134758182695, -0.06217013151235991, \n-0.05905529159312335, -0.04927743270606937]\n\n\n\n\n\n","category":"function"},{"location":"guide/doublemachinelearning/#Double-Machine-Learning","page":"Double Machine Learning","title":"Double Machine Learning","text":"","category":"section"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"Doubly robust estimation estimates separate models for the treatment and outcome variables  and weights the outcome estimates by the treatment estimates. This allows one to model more  complex, nonlinear relationships between the treatment and outcome variables. Additonally,  double machine learning is doubly robust, which meants that only one of the models has to be  specified correctly to produce an unbiased estimate of the causal effect. This  implementation also uses cross fitting to avoid regularization bias. The main steps for  using doubly robust estimation in CausalELM are below.","category":"page"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"For more information see:     Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen,      Whitney Newey, and James Robins. \"Double/debiased machine learning for treatment and      structural parameters.\" (2018): C1-C68.","category":"page"},{"location":"guide/doublemachinelearning/##-Step-1:-Initialize-a-Model","page":"Double Machine Learning","title":"# Step 1: Initialize a Model","text":"","category":"section"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"The DoubleMachineLearning constructor takes four arguments, an array of covariates for the  outcome model, an array of covariates for the treatment model, a vector of outcomes, and a  vector of treatment statuses.","category":"page"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"# Create some data with a binary treatment\nX, Xₚ, Y, T =  rand(100, 5), rand(100, 4), rand(100), [rand()<0.4 for i in 1:100]\n\ndml = DoubleMachineLearning(X, Xₚ, Y, T)","category":"page"},{"location":"guide/doublemachinelearning/#Step-2:-Estimate-the-Causal-Effect","page":"Double Machine Learning","title":"Step 2: Estimate the Causal Effect","text":"","category":"section"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"To estimate the causal effect, we call estimatecausaleffect! on the model above.","category":"page"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"# we could also estimate the ATT by passing quantity_of_interest=\"ATT\"\nestimate_causal_effect!(dml)","category":"page"},{"location":"guide/doublemachinelearning/#Get-a-Summary","page":"Double Machine Learning","title":"Get a Summary","text":"","category":"section"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"We can get a summary that includes a p-value and standard error estimated via asymptotic  randomization inference by passing our model to the summarize method.","category":"page"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"summarize(dml)","category":"page"},{"location":"guide/doublemachinelearning/#Step-4:-Validate-the-Model","page":"Double Machine Learning","title":"Step 4: Validate the Model","text":"","category":"section"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model's  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  probability of treatment. If the matrix is empty, none of the observations have an estimated  zero probability of treatment, which implies the positivity assumption is satisfied.","category":"page"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"For a thorough review of casual inference assumptions see:     Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and      Francis, 2024. ","category":"page"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"For more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. \"Sensitivity analysis in observational research:      introducing the E-value.\" Annals of internal medicine 167, no. 4 (2017): 268-274.","category":"page"},{"location":"guide/doublemachinelearning/","page":"Double Machine Learning","title":"Double Machine Learning","text":"validate(g_computer)","category":"page"},{"location":"reference/activations/#Activation-Functions","page":"Activation Functions","title":"Activation Functions","text":"","category":"section"},{"location":"reference/activations/","page":"Activation Functions","title":"Activation Functions","text":"Activation functions for CausalELM estimators","category":"page"},{"location":"reference/activations/","page":"Activation Functions","title":"Activation Functions","text":"CausalELM.ActivationFunctions\nCausalELM.ActivationFunctions.binary_step\nCausalELM.ActivationFunctions.σ\nCausalELM.ActivationFunctions.tanh\nCausalELM.ActivationFunctions.relu\nCausalELM.ActivationFunctions.leaky_relu\nCausalELM.ActivationFunctions.swish\nCausalELM.ActivationFunctions.softmax\nCausalELM.ActivationFunctions.softplus\nCausalELM.ActivationFunctions.gelu\nCausalELM.ActivationFunctions.gaussian\nCausalELM.ActivationFunctions.hard_tanh\nCausalELM.ActivationFunctions.elish\nCausalELM.ActivationFunctions.fourier","category":"page"},{"location":"reference/activations/#CausalELM.ActivationFunctions","page":"Activation Functions","title":"CausalELM.ActivationFunctions","text":"Activation functions for Extreme Learning machines\n\n\n\n\n\n","category":"module"},{"location":"reference/activations/#CausalELM.ActivationFunctions.binary_step","page":"Activation Functions","title":"CausalELM.ActivationFunctions.binary_step","text":"binary_step(x)\n\nApply the binary step activation function to a real number.\n\nExamples\n\njulia> binary_step(1)\n1\n\n\n\n\n\nbinary_step(x)\n\nApply the binary step activation function to an array.\n\nExamples\n\njulia> binary_step([-1000, 100, 1, 0, -0.001, -3])\n[0, 1, 1, 1, 0, 0]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.σ","page":"Activation Functions","title":"CausalELM.ActivationFunctions.σ","text":"σ(x)\n\nApply the sigmoid activation function to a real number.\n\nExamples\n\njulia> σ(1)\n0.7310585786300049\n\n\n\n\n\nσ(x)\n\nApply the sigmoid activation function to an array.\n\nExamples\n\njulia> σ([1, 0])\n[0.7310585786300049, 0.5]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.tanh","page":"Activation Functions","title":"CausalELM.ActivationFunctions.tanh","text":"tanh(x)\n\nApply the tanh activation function to an array.\n\nThis is just a vectorized version of Base.tanh\n\nExamples\n\njulia> tanh([1, 0])\n[0.7615941559557649, 0.0]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.relu","page":"Activation Functions","title":"CausalELM.ActivationFunctions.relu","text":"relu(x)\n\nApply the ReLU activation function to a real number.\n\nExamples\n\njulia> relu(1)\n1\n\n\n\n\n\nrelu(x)\n\nApply the ReLU activation function to an array.\n\nExamples\n\njulia> relu([1, 0, -1])\n[1, 0, 0]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.leaky_relu","page":"Activation Functions","title":"CausalELM.ActivationFunctions.leaky_relu","text":"leaky_relu(x)\n\nApply the leaky ReLU activation function to a real number.\n\nExamples\n\njulia> leaky_relu(1)\n1\n\n\n\n\n\nleaky_relu(x)\n\nApply the leaky ReLU activation function to an array.\n\nExamples\n\njulia> leaky_relu([-0.01, 0, 1])\n[1, 0, 0]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.swish","page":"Activation Functions","title":"CausalELM.ActivationFunctions.swish","text":"swish(x)\n\nApply the swish activation function to a real number.\n\nExamples\n\njulia> swish(1)\n0.7310585786300049\n\n\n\n\n\nswish(x)\n\nApply the swish activation function to an array.\n\nExamples\n\njulia> swish([1, 0, -1])\n[0.7310585786300049, 0, -0.2689414213699951]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.softmax","page":"Activation Functions","title":"CausalELM.ActivationFunctions.softmax","text":"softmax(x)\n\nApply the softmax activation function to a real number.\n\nFor numbers that have large absolute values this function may become numerically unstable.\n\nExamples\n\njulia> softmax(1)\n2.718281828459045\n\n\n\n\n\nsoftmax(x)\n\nApply the softmax activation function to an array.\n\nFor numbers that have large absolute values this function might be numerically unstable.\n\nExamples\n\njulia> softmax([1, -1])\n[2.718281828459045, -0.36787944117144233]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.softplus","page":"Activation Functions","title":"CausalELM.ActivationFunctions.softplus","text":"softplus(x)\n\nApply the softplus activation function to a real number.\n\nExamples\n\njulia> softplus(1)\n1.3132616875182228\n\n\n\n\n\nsoftplus(x)\n\nApply the softplus activation function to an array.\n\nExamples\n\njulia> softplus([1, -1])\n[1.3132616875182228, 0.31326168751822286]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.gelu","page":"Activation Functions","title":"CausalELM.ActivationFunctions.gelu","text":"gelu(x)\n\nApply the GeLU activation function to a real number.\n\nExamples\n\njulia> gelu(1)\n0.8411919906082768\n\n\n\n\n\ngelu(x)\n\nApply the GeLU activation function to an array.\n\nExamples\n\njulia> gelu([-1, 0, 1])\n[-0.15880800939172324, 0, 0.8411919906082768]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.gaussian","page":"Activation Functions","title":"CausalELM.ActivationFunctions.gaussian","text":"gaussian(x)\n\nApply the gaussian activation function to a real number.\n\nExamples\n\njulia> gaussian(1)\n0.11443511435028261\n\n\n\n\n\ngaussian(x)\n\nApply the gaussian activation function to an array.\n\nExamples\n\njulia> gaussian([1, -1])\n[0.36787944117144233, 0.36787944117144233]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.hard_tanh","page":"Activation Functions","title":"CausalELM.ActivationFunctions.hard_tanh","text":"hard_tanh(x)\n\nApply the hard_tanh activation function to a real number.\n\nExamples\n\njulia> hard_tanh(-2)\n-1\n\n\n\n\n\nhard_tanh(x)\n\nApply the hard_tanh activation function to an array.\n\nExamples\n\njulia> hard_tanh([-2, 0, 2])\n[-1, 0, 1]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.elish","page":"Activation Functions","title":"CausalELM.ActivationFunctions.elish","text":"elish(x)\n\nApply the ELiSH activation function to a real number.\n\nExamples\n\njulia> elish(1)\n0.7310585786300049\n\n\n\n\n\nelish(x)\n\nApply the ELiSH activation function to an array.\n\nExamples\n\njulia> elish([-1, 1])\n[-0.17000340156854793, 0.7310585786300049]\n\n\n\n\n\n","category":"function"},{"location":"reference/activations/#CausalELM.ActivationFunctions.fourier","page":"Activation Functions","title":"CausalELM.ActivationFunctions.fourier","text":"fourrier(x)\n\nApply the Fourier activation function to a real number.\n\nExamples\n\njulia> fourier(1)\n0.8414709848078965\n\n\n\n\n\nfourrier(x)\n\nApply the Fourier activation function to an array.\n\nExamples\n\njulia> fourier([-1, 1])\n[-0.8414709848078965, 0.8414709848078965]\n\n\n\n\n\n","category":"function"},{"location":"reference/base/#Base-Models","page":"Base Models","title":"Base Models","text":"","category":"section"},{"location":"reference/base/","page":"Base Models","title":"Base Models","text":"Extreme learning machines and L2 regularized extreme learning machines for CausalELM estimators","category":"page"},{"location":"reference/base/","page":"Base Models","title":"Base Models","text":"CausalELM.Models\nCausalELM.Models.ExtremeLearningMachine\nCausalELM.Models.ExtremeLearner\nCausalELM.Models.RegularizedExtremeLearner\nCausalELM.Models.fit!\nCausalELM.Models.predict\nCausalELM.Models.predict_counterfactual!\nCausalELM.Models.placebo_test\nCausalELM.Models.ridge_constant\nCausalELM.Models.set_weights_biases","category":"page"},{"location":"reference/base/#CausalELM.Models","page":"Base Models","title":"CausalELM.Models","text":"Base models to perform extreme learning with and without L2 penalization.\n\nFor details on Extreme learning machines see;     Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. \"Extreme learning machine: theory      and applications.\" Neurocomputing 70, no. 1-3 (2006): 489-501.\n\nFor details on Extreme learning machines with an L2 penalty see:     Li, Guoqiang, and Peifeng Niu. \"An enhanced extreme learning machine based on ridge      regression for regression.\" Neural Computing and Applications 22, no. 3 (2013):      803-810.\n\n\n\n\n\n","category":"module"},{"location":"reference/base/#CausalELM.Models.ExtremeLearningMachine","page":"Base Models","title":"CausalELM.Models.ExtremeLearningMachine","text":"Abstract type that includes vanilla and L2 regularized Extreme Learning Machines\n\n\n\n\n\n","category":"type"},{"location":"reference/base/#CausalELM.Models.ExtremeLearner","page":"Base Models","title":"CausalELM.Models.ExtremeLearner","text":"Struct to hold data for an Extreme Learning machine\n\n\n\n\n\n","category":"type"},{"location":"reference/base/#CausalELM.Models.RegularizedExtremeLearner","page":"Base Models","title":"CausalELM.Models.RegularizedExtremeLearner","text":"Struct to hold data for a regularized Extreme Learning Machine\n\n\n\n\n\n","category":"type"},{"location":"reference/base/#CausalELM.Models.fit!","page":"Base Models","title":"CausalELM.Models.fit!","text":"fit!(model)\n\nMake predictions with an ExtremeLearner.\n\nFor more details see:      Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. \"Extreme learning machine: theory      and applications.\" Neurocomputing 70, no. 1-3 (2006): 489-501.\n\nExamples julia-repl julia> m1 = ExtremeLearner(x, y, 10, σ)  Extreme Learning Machine with 10 hidden neurons  julia> f1 = fit!(m1)  [-4.403356409043448, -5.577616954029608, -2.1732800642523595, 0.9669137012255704,   -3.6474913410560013, -4.206228346376102, -7.575391282978456, 4.528774205936467,   -2.4741301876094655, 40.642730531608635, -11.058942121275233]\n\n\n\n\n\nfit!(model)\n\nFit a Regularized Extreme Learner.\n\nFor more details see:      Li, Guoqiang, and Peifeng Niu. \"An enhanced extreme learning machine based on ridge      regression for regression.\" Neural Computing and Applications 22, no. 3 (2013):      803-810.\n\nExamples julia-repl julia> m1 = RegularizedExtremeLearner(x, y, 10, σ)  Regularized Extreme Learning Machine with 10 hidden neurons  julia> f1 = fit!(m1)  [-4.403356409043448, -5.577616954029608, -2.1732800642523595, 0.9669137012255704,   -3.6474913410560013, -4.206228346376102, -7.575391282978456, 4.528774205936467,   -2.4741301876094655, 40.642730531608635, -11.058942121275233]\n\n\n\n\n\n","category":"function"},{"location":"reference/base/#CausalELM.Models.predict","page":"Base Models","title":"CausalELM.Models.predict","text":"predict(model, X)\n\nUse an ExtremeLearningMachine to make predictions.\n\nFor more details see:      Huang G-B, Zhu Q-Y, Siew C. Extreme learning machine: theory and applications.      Neurocomputing. 2006;70:489–501. https://doi.org/10.1016/j.neucom.2005.12.126\n\nExamples julia-repl julia> m1 = ExtremeLearner(x, y, 10, σ)  Extreme Learning Machine with 10 hidden neurons  julia> f1 = fit(m1, sigmoid)  [-4.403356409043448, -5.577616954029608, -2.1732800642523595, 0.9669137012255704,   -3.6474913410560013, -4.206228346376102, -7.575391282978456, 4.528774205936467,   -2.4741301876094655, 40.642730531608635, -11.058942121275233]  julia> predict(m1, [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0])  [9.811656638113011e-16, 0.9999999999999962, -9.020553785284482e-17, 0.9999999999999978]\n\n\n\n\n\n","category":"function"},{"location":"reference/base/#CausalELM.Models.predict_counterfactual!","page":"Base Models","title":"CausalELM.Models.predict_counterfactual!","text":"predictcounterfactual(model, X)\n\nUse an ExtremeLearningMachine to predict the counterfactual.\n\nThis should be run with the observed covariates. To use synthtic data for what-if      scenarios use predict.\n\nSee also predict.\n\nExamples julia-repl julia> m1 = ExtremeLearner(x, y, 10, σ)  Extreme Learning Machine with 10 hidden neurons  julia> f1 = fit(m1, sigmoid)  [-4.403356409043448, -5.577616954029608, -2.1732800642523595, 0.9669137012255704,   -3.6474913410560013, -4.206228346376102, -7.575391282978456, 4.528774205936467,   -2.4741301876094655, 40.642730531608635, -11.058942121275233]  julia> predictcounterfactual(m1, [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0])  [9.811656638113011e-16, 0.9999999999999962, -9.020553785284482e-17, 0.9999999999999978]\n\n\n\n\n\n","category":"function"},{"location":"reference/base/#CausalELM.Models.placebo_test","page":"Base Models","title":"CausalELM.Models.placebo_test","text":"placebo_test(model)\n\nConduct a placebo test.\n\nThis method makes predictions for the post-event or post-treatment period using data  in the pre-event or pre-treatment period and the post-event or post-treament. If there is a statistically significant difference between these predictions the study design may be flawed. Due to the multitude of significance tests for time series data, this function returns the predictions but does not test for statistical significance.\n\nExamples julia-repl julia> m1 = ExtremeLearner(x, y, 10, σ)  Extreme Learning Machine with 10 hidden neurons  julia> f1 = fit(m1, sigmoid)  [-4.403356409043448, -5.577616954029608, -2.1732800642523595, 0.9669137012255704,   -3.6474913410560013, -4.206228346376102, -7.575391282978456, 4.528774205936467,   -2.4741301876094655, 40.642730531608635, -11.058942121275233]  julia> predictcounterfactual(m1, [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0])  [9.811656638113011e-16, 0.9999999999999962, -9.020553785284482e-17, 0.9999999999999978]  julia> placebo_test(m1)  ([9.811656638113011e-16, 0.9999999999999962, -9.020553785284482e-17, 0.9999999999999978],  [0.5, 0.4, 0.3, 0.2])\n\n\n\n\n\n","category":"function"},{"location":"reference/base/#CausalELM.Models.ridge_constant","page":"Base Models","title":"CausalELM.Models.ridge_constant","text":"ridge_constant(model)\n\nCalculate the L2 penalty for a regularized extreme learning machine.\n\nFor more information see:      Li, Guoqiang, and Peifeng Niu. \"An enhanced extreme learning machine based on ridge      regression for regression.\" Neural Computing and Applications 22, no. 3 (2013):      803-810.\n\nExamples julia-repl julia> m1 = RegularizedExtremeLearner(x, y, 10, σ)  Extreme Learning Machine with 10 hidden neurons  julia> ridge_constant(m1)  0.26789338524662887\n\n\n\n\n\n","category":"function"},{"location":"reference/base/#CausalELM.Models.set_weights_biases","page":"Base Models","title":"CausalELM.Models.set_weights_biases","text":"set_weights_biases(model)\n\nCalculate the weights and biases for an extreme learning machine or regularized extreme  learning machine.\n\nFor details see;     Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. \"Extreme learning machine: theory      and applications.\" Neurocomputing 70, no. 1-3 (2006): 489-501.\n\nExamples julia-repl julia> m1 = RegularizedExtremeLearner(x, y, 10, σ)  Extreme Learning Machine with 10 hidden neurons  julia> set_weights_biases(m1)\n\n\n\n\n\n","category":"function"},{"location":"reference/estimation/#ATE/ATT/ITT-Estimation","page":"ATE/ATT/ITE Estimation","title":"ATE/ATT/ITT Estimation","text":"","category":"section"},{"location":"reference/estimation/","page":"ATE/ATT/ITE Estimation","title":"ATE/ATT/ITE Estimation","text":"Structs and methods to estimate the ATE, ATT, ITT, and change over time from observational research designs.","category":"page"},{"location":"reference/estimation/","page":"ATE/ATT/ITE Estimation","title":"ATE/ATT/ITE Estimation","text":"CausalELM.Estimators\nCausalELM.Estimators.CausalEstimator\nCausalELM.Estimators.InterruptedTimeSeries\nCausalELM.Estimators.GComputation\nCausalELM.Estimators.DoubleMachineLearning\nCausalELM.Estimators.estimate_causal_effect!\nCausalELM.Estimators.first_stage!\nCausalELM.Estimators.ate!\nCausalELM.Estimators.predict_propensity_score\nCausalELM.Estimators.predict_control_outcomes\nCausalELM.Estimators.predict_treatment_outcomes\nCausalELM.Estimators.crossfitting_sets\nCausalELM.Estimators.moving_average","category":"page"},{"location":"reference/estimation/#CausalELM.Estimators","page":"ATE/ATT/ITE Estimation","title":"CausalELM.Estimators","text":"Estimate causal effects with interrupted time series analysis, G-computation, and double  machine learning using Extreme Learning machines.\n\n\n\n\n\n","category":"module"},{"location":"reference/estimation/#CausalELM.Estimators.CausalEstimator","page":"ATE/ATT/ITE Estimation","title":"CausalELM.Estimators.CausalEstimator","text":"Abstract type for GComputation and DoubleMachineLearning\n\n\n\n\n\n","category":"type"},{"location":"reference/estimation/#CausalELM.Estimators.InterruptedTimeSeries","page":"ATE/ATT/ITE Estimation","title":"CausalELM.Estimators.InterruptedTimeSeries","text":"Container for the results of an interrupted time series analysis\n\n\n\n\n\n","category":"type"},{"location":"reference/estimation/#CausalELM.Estimators.GComputation","page":"ATE/ATT/ITE Estimation","title":"CausalELM.Estimators.GComputation","text":"Container for the results of G-Computation\n\n\n\n\n\n","category":"type"},{"location":"reference/estimation/#CausalELM.Estimators.DoubleMachineLearning","page":"ATE/ATT/ITE Estimation","title":"CausalELM.Estimators.DoubleMachineLearning","text":"Container for the results of a double machine learning estimator\n\n\n\n\n\n","category":"type"},{"location":"reference/estimation/#CausalELM.estimate_causal_effect!","page":"ATE/ATT/ITE Estimation","title":"CausalELM.estimate_causal_effect!","text":"estimate_causal_effect!(m)\n\nEstimate the CATE using a metalearner.\n\nFor an overview of metalearning see:\n\nKünzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. \"Metalearners for \nestimating heterogeneous treatment effects using machine learning.\" Proceedings of the \nnational academy of sciences 116, no. 10 (2019): 4156-4165.\n\nExamples\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m4 = SLearner(X, Y, T)\njulia> estimate_causal_effect!(m4)\n[0.20729633391630697, 0.20729633391630697, 0.20729633391630692, 0.20729633391630697, \n0.20729633391630697, 0.20729633391630697, 0.20729633391630697, 0.20729633391630703, \n0.20729633391630697, 0.20729633391630697  …  0.20729633391630703, 0.20729633391630697, \n0.20729633391630692, 0.20729633391630703, 0.20729633391630697, 0.20729633391630697, \n0.20729633391630692, 0.20729633391630697, 0.20729633391630697, 0.20729633391630697]\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m5 = TLearner(X, Y, T)\njulia> estimatecausaleffect!(m5)\n[0.0493951571746305, 0.049395157174630444, 0.0493951571746305, 0.049395157174630444, \n0.04939515717463039, 0.04939515717463039, 0.04939515717463039, 0.04939515717463039, \n0.049395157174630444, 0.04939515717463061  …  0.0493951571746305, 0.04939515717463039, \n0.0493951571746305, 0.04939515717463039, 0.0493951571746305, 0.04939515717463039, \n0.04939515717463039, 0.049395157174630444, 0.04939515717463039, 0.049395157174630444]\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m1 = XLearner(X, Y, T)\njulia> estimatecausaleffect!(m1)\n[-0.025012644892878473, -0.024634294305967294, -0.022144246680543364, -0.023983138957276127, \n-0.024756239357838557, -0.019409519377053822, -0.02312807640357356, -0.016967113188439076, \n-0.020188871831409317, -0.02546526148141366  …  -0.019811641136866287, \n-0.020780821058711863, -0.013588359417922776, -0.020438648396328824, -0.016169487825519843, \n-0.024031422484491572, -0.01884713946778991, -0.021163590874553318, -0.014607310062509895, \n-0.022449034332142046]\n\n\n\n\n\nestimate_causal_effect!(its)\n\nEstimate the effect of an event relative to a predicted counterfactual.\n\nExamples\n\njulia> X₀, Y₀, X₁, Y₁ =  rand(100, 5), rand(100), rand(10, 5), rand(10)\njulia> m1 = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)\njulia> estimate_causal_effect!(m1)\n0.25714308\n\n\n\n\n\nestimate_causal_effect!(g)\n\nEstimate a causal effect of interest using G-Computation.\n\nIf treatents are administered at multiple time periods, the effect will be estimated as the  average difference between the outcome of being treated in all periods and being treated in  no periods.For example, given that individuals 1, 2, ..., i ∈ I recieved either a treatment  or a placebo in p different periods, the model would estimate the average treatment effect  as E[Yᵢ|T₁=1, T₂=1, ... Tₚ=1, Xₚ] - E[Yᵢ|T₁=0, T₂=0, ... Tₚ=0, Xₚ].\n\nExamples\n\njulia> X, Y, T =  rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m2 = GComputation(X, Y, T)\njulia> estimate_causal_effect!(m2)\n0.31067439\n\n\n\n\n\nestimate_causal_effect!(DML)\n\nEstimate a causal effect of interest using double machine learning.\n\nUnlike other estimators, this method does not support time series or panel data. This method  also does not work as well with smaller datasets because it estimates separate outcome  models for the treatment and control groups.\n\nExamples\n\njulia> X, Xₚ, Y, T =  rand(100, 5), rand(100, 5), rand(100), [rand()<0.4 for i in 1:100]\njulia> m3 = DoubleMachineLearning(X, Xₚ, Y, T)\njulia> estimate_causal_effect!(m3)\n0.31067439\n\n\n\n\n\n","category":"function"},{"location":"reference/estimation/#CausalELM.Estimators.moving_average","page":"ATE/ATT/ITE Estimation","title":"CausalELM.Estimators.moving_average","text":"moving_average(g)\n\nCalculates a cumulative moving average.\n\nExamples\n\njulia> moving_average([1, 2, 3])\n3-element Vector{Float64}\n1.0\n1.5\n2.0\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#Model-Validation","page":"Model Validation","title":"Model Validation","text":"","category":"section"},{"location":"reference/validation/","page":"Model Validation","title":"Model Validation","text":"Methods to validate causal modeling assumptions of an estimated model","category":"page"},{"location":"reference/validation/","page":"Model Validation","title":"Model Validation","text":"CausalELM.ModelValidation\nCausalELM.ModelValidation.validate\nCausalELM.ModelValidation.covariate_independence\nCausalELM.ModelValidation.omitted_predictor\nCausalELM.ModelValidation.sup_wald\nCausalELM.ModelValidation.p_val\nCausalELM.ModelValidation.counterfactual_consistency\nCausalELM.ModelValidation.exchangeability\nCausalELM.ModelValidation.e_value\nCausalELM.ModelValidation.positivity\nCausalELM.ModelValidation.sums_of_squares\nCausalELM.ModelValidation.class_pointers\nCausalELM.ModelValidation.backtrack_to_find_breaks\nCausalELM.ModelValidation.variance\nCausalELM.ModelValidation.best_splits\nCausalELM.ModelValidation.group_by_class\nCausalELM.ModelValidation.jenks_breaks\nCausalELM.ModelValidation.fake_treatments\nCausalELM.ModelValidation.sdam\nCausalELM.ModelValidation.scdm\nCausalELM.ModelValidation.gvf","category":"page"},{"location":"reference/validation/#CausalELM.ModelValidation","page":"Model Validation","title":"CausalELM.ModelValidation","text":"Methods to test the sensitivity of interrupted time series estimators, G-computation, double  machine learning, S-learners, T-learners, and X-learners to violations of their modeling  assumptions.\n\n\n\n\n\n","category":"module"},{"location":"reference/validation/#CausalELM.ModelValidation.validate","page":"Model Validation","title":"CausalELM.ModelValidation.validate","text":"validate(its; n, low, high)\n\nTest the validity of an estimated interrupted time series analysis.\n\nThis method coducts a Chow Test, a Wald supremeum test, and tests the model's sensitivity to  confounders. The Chow Test tests for structural breaks in the covariates between the time  before and after the event. p-values represent the proportion of times the magnitude of the  break in a covariate would have been greater due to chance. Lower p-values suggest a higher  probability the event effected the covariates and they cannot provide unbiased  counterfactual predictions. The Wald supremum test finds the structural break with the  highest Wald statistic. If this is not the same as the hypothesized break, it could indicate  an anticipation effect, a confounding event, or that the intervention or policy took place  in multiple phases. p-values represent the proportion of times we would see a larger Wald  statistic if the data points were randomly allocated to pre and post-event periods for the  predicted structural break. Ideally, the hypothesized break will be the same as the  predicted break and it will also have a low p-value. The omitted predictors test adds  normal random variables with uniform noise as predictors. If the included covariates are  good predictors of the counterfactual outcome, adding irrelevant predictors should not have  a large effect on the predicted counterfactual outcomes or the estimated effect.\n\nFor more details on the assumptions and validity of interrupted time series designs, see:     Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single      interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.\n\nNote that this method does not implement the second test in Baicker and Svoronos because \n\nthe estimator in this package models the relationship between covariates and the outcome and  uses an extreme learning machine instead of linear regression, so variance in the outcome  across different bins is not much of an issue.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> X₀, Y₀, X₁, Y₁ =  rand(100, 5), rand(100), rand(10, 5), rand(10)\njulia> m1 = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)\njulia> estimate_causal_effect!(m1)\n[0.25714308]\njulia> validate(m1)\n{\"Task\" => \"Regression\", \"Regularized\" => true, \"Activation Function\" => relu, \n\"Validation Metric\" => \"mse\",\"Number of Neurons\" => 2, \n\"Number of Neurons in Approximator\" => 10, \"β\" => [0.25714308], \n\"Causal Effect\" => -3.9101138, \"Standard Error\" => 1.903434356, \"p-value\" = 0.00123356}\n\n\n\n\n\nvalidate(m; num_treatments, min, max)\n\nThis method tests the counterfactual consistency, exchangeability, and positivity  assumptions required for causal inference. It should be noted that consistency and  exchangeability are not directly testable, so instead, these tests do not provide definitive  evidence of a violation of these assumptions. To probe the counterfactual consistency  assumption, we assume there were multiple levels of treatments and find them by binning the dependent vairable for treated observations using Jenks breaks. The optimal number of breaks  between 2 and num_treatments is found using the elbow method. Using these hypothesized  treatment assignemnts, this method compares the MSE of linear regressions using the observed  and hypothesized treatments. If the counterfactual consistency assumption holds then the  difference between the MSE with hypothesized treatments and the observed treatments should  be positive because the hypothesized treatments should not provide useful information. If  it is negative, that indicates there was more useful information provided by the  hypothesized treatments than the observed treatments or that there is an unobserved  confounder. Next, this methods tests the model's sensitivity to a violation of the  exchangeability assumption by calculating the E-value, which is the minimum strength of  association, on the risk ratio scale, that an unobserved confounder would need to have with  the treatment and outcome variable to fully explain away the estimated effect. Thus, higher  E-values imply the model is more robust to a violation of the exchangeability assumption.  Finally, this method tests the positivity assumption by estimating propensity scores. Rows in the matrix are levels of covariates that have a zero probability of treatment. If the  matrix is empty, none of the observations have an estimated zero probability of treatment,  which implies the positivity assumption is satisfied.\n\nFor a thorough review of casual inference assumptions see:     Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and      Francis, 2024. \n\nFor more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. \"Sensitivity analysis in observational research:      introducing the E-value.\" Annals of internal medicine 167, no. 4 (2017): 268-274.\n\nExamples julia-repl julia> x, y, t = rand(100, 5), vec(rand(1:100, 100, 1)),      Float64.([rand()<0.4 for i in 1:100]) julia> g_computer = GComputation(x, y, t, temporal=false) julia> estimate_causal_effect!(g_computer) julia> validate(g_computer) 2.7653668647301795\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.covariate_independence","page":"Model Validation","title":"CausalELM.ModelValidation.covariate_independence","text":"covariate_independence(its; n)\n\nTest for independence between covariates and the event or intervention.\n\nThis is a Chow Test for covariates with p-values estimated via randomization inference. The  p-values are the proportion of times randomly assigning observations to the pre or  post-intervention period would have a larger estimated effect on the the slope of the  covariates. The lower the p-values, the more likely it is that the event/intervention  effected the covariates and they cannot provide an unbiased prediction of the counterfactual  outcomes.\n\nFor more information on using a Chow Test to test for structural breaks see:     Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single      interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> x₀, y₀, x₁, y₁ = (Float64.(rand(1:5, 100, 5)), randn(100), rand(1:5, (10, 5)), \n           randn(10))\njulia> its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)\njulia> estimate_causal_effect!(its)\njulia> covariate_independence(its)\nDict(\"Column 1 p-value\" => 0.421, \"Column 5 p-value\" => 0.07, \"Column 3 p-value\" => 0.01, \n\"Column 2 p-value\" => 0.713, \"Column 4 p-value\" => 0.043)\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.omitted_predictor","page":"Model Validation","title":"CausalELM.ModelValidation.omitted_predictor","text":"omitted_predictor(its; n)\n\nSee how an omitted predictor/variable could change the results of an interrupted time series  analysis.\n\nThis method reestimates interrupted time series models with uniform random variables. If the  included covariates are good predictors of the counterfactual outcome, adding a random  variable as a covariate should not have a large effect on the predicted counterfactual  outcomes and therefore the estimated average effect.\n\nFor more information on using a Chow Test to test for structural breaks see:     Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single      interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> x₀, y₀, x₁, y₁ = (Float64.(rand(1:5, 100, 5)), randn(100), rand(1:5, (10, 5)), \n           randn(10))\njulia> its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)\njulia> estimate_causal_effect!(its)\njulia> omitted_predictor(its)\nDict(\"Mean Biased Effect/Original Effect\" => -0.1943184744720332, \"Median Biased \nEffect/Original Effect\" => -0.1881814122689084, \"Minimum Biased Effect/Original Effect\" => \n-0.2725194360603799, \"Maximum Biased Effect/Original Effect\" => -0.1419197976977072)\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.sup_wald","page":"Model Validation","title":"CausalELM.ModelValidation.sup_wald","text":"sup_wald(its; low, high, n)\n\nCheck if the predicted structural break is the hypothesized structural break.\n\nThis method conducts Wald tests and identifies the structural break with the highest Wald  statistic. If this break is not the same as the hypothesized break, it could indicate an  anticipation effect, confounding by some other event or intervention, or that the  intervention or policy took place in multiple phases. p-values are estimated using  approximate randomization inference and represent the proportion of times we would see a  larger Wald statistic if the data points were randomly allocated to pre and post-event  periods for the predicted structural break.\n\nFor more information on using a Chow Test to test for structural breaks see:     Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single      interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.\n\nFor a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf\n\nExamples\n\njulia> x₀, y₀, x₁, y₁ = (Float64.(rand(1:5, 100, 5)), randn(100), rand(1:5, (10, 5)), \n           randn(10))\njulia> its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)\njulia> estimate_causal_effect!(its)\njulia> sup_wald(its)\nDict{String, Real}(\"Wald Statistic\" => 58.16649796321913, \"p-value\" => 0.005, \"Predicted \nBreak Point\" => 39, \"Hypothesized Break Point\" => 100)\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.p_val","page":"Model Validation","title":"CausalELM.ModelValidation.p_val","text":"p_val(x, y, β; n, wald)\n\nEstimate the p-value for the hypothesis that an event had a statistically significant effect  on the slope of a covariate using randomization inference.\n\nExamples\n\njulia> x, y, β = reduce(hcat, (float(rand(0:1, 10)), ones(10))), rand(10), 0.5\njulia> p_val(x, y, β)\n0.98\njulia> p_val(x, y, β; n=100, wald=true)\n0.08534054\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.counterfactual_consistency","page":"Model Validation","title":"CausalELM.ModelValidation.counterfactual_consistency","text":"counterfactual_consistency(m; num_treatments)\n\nExamine the counterfactual consistency assumption. First, this function generates Jenks  breaks based on outcome values for the treatment group. Then, it replaces treatment statuses  with the numbers corresponding to each group. Next, it runs two linear regressions on for  the treatment group, one with and one without the fake treatment assignemnts generated by  the Jenks breaks. Finally, it subtracts the mean squared error from the regression with real  data from the mean squared error from the regression with the fake treatment statuses. If  this number is negative, it might indicate a violation of the counterfactual consistency  assumption or omitted variable bias.\n\nFor a primer on G-computation and its assumptions see:     Naimi, Ashley I., Stephen R. Cole, and Edward H. Kennedy. \"An introduction to g      methods.\" International journal of epidemiology 46, no. 2 (2017): 756-762.\n\nExamples\n\njulia> x, y, t = rand(100, 5), vec(rand(1:100, 100, 1)), \n    Float64.([rand()<0.4 for i in 1:100])\njulia> g_computer = GComputation(x, y, t, temporal=false)\njulia> estimate_causal_effect!(g_computer)\njulia> counterfactual_consistency(g_computer)\n2.7653668647301795\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.exchangeability","page":"Model Validation","title":"CausalELM.ModelValidation.exchangeability","text":"exchangeability(model)\n\nTest the sensitivity of a G-computation or doubly robust estimator or metalearner to a  violation of the exchangeability assumption.\n\nFor more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. \"Sensitivity analysis in observational research:      introducing the E-value.\" Annals of internal medicine 167, no. 4 (2017): 268-274.\n\nExamples\n\njulia> x, y, t = rand(100, 5), vec(rand(1:100, 100, 1)), \n    Float64.([rand()<0.4 for i in 1:100])\njulia> g_computer = GComputation(x, y, t, temporal=false)\njulia> estimate_causal_effect!(g_computer)\njulia> e_value(g_computer)\n1.13729886008143832\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.e_value","page":"Model Validation","title":"CausalELM.ModelValidation.e_value","text":"e_value(model)\n\nTest the sensitivity of an estimator to a violation of the exchangeability assumption.\n\nFor more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. \"Sensitivity analysis in observational research:      introducing the E-value.\" Annals of internal medicine 167, no. 4 (2017): 268-274.\n\nExamples\n\njulia> x, y, t = rand(100, 5), vec(rand(1:100, 100, 1)), \n    Float64.([rand()<0.4 for i in 1:100])\njulia> g_computer = GComputation(x, y, t, temporal=false)\njulia> estimate_causal_effect!(g_computer)\njulia> e_value(g_computer)\n2.2555405766985125\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.positivity","page":"Model Validation","title":"CausalELM.ModelValidation.positivity","text":"positivity(model, min, max)\n\nFind likely violations of the positivity assumption.\n\nThis method uses an extreme learning machine or regularized extreme learning machine to  estimate probabilities of treatment. The returned matrix, which may be empty, are the  covariates that have a (near) zero probability of treatment or near zero probability of  being assigned to the control group, whith their entry in the last column being their  estimated treatment probability. In other words, they likely violate the positivity  assumption.\n\nExamples\n\njulia> x, y, t = rand(100, 5), vec(rand(1:100, 100, 1)), \n    Float64.([rand()<0.4 for i in 1:100])\njulia> g_computer = GComputation(x, y, t, temporal=false)\njulia> estimate_causal_effect!(g_computer)\njulia> positivity(g_computer)\n0×5 Matrix{Float64}\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.sums_of_squares","page":"Model Validation","title":"CausalELM.ModelValidation.sums_of_squares","text":"sums_of_squares(data, num_classes)\n\nCalculate the minimum sum of squares for each data point and class for the Jenks breaks      algorithm.\n\nExamples\n\njulia> sums_of_squares([1, 2, 3, 4, 5], 2)\n5×2 Matrix{Real}:\n 0.0       0.0\n 0.25      0.25\n 0.666667  0.666667\n 1.25      1.16667\n 2.0       1.75\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.class_pointers","page":"Model Validation","title":"CausalELM.ModelValidation.class_pointers","text":"class_pointers(data, num_classes, sums_of_sqs)\n\nCompute class pointers that minimize the sum of squares for Jenks breaks.\n\nExamples\n\njulia> sums_squares = sums_of_sqs::Matrix{Float64}\n5×2 Matrix{Float64}:\n 0.0       0.0\n 0.25      0.25\n 0.666667  0.666667\n 1.25      1.16667\n 2.0       1.75\njulia> class_pointers([1, 2, 3, 4, 5], 2, sums_squares)\n5×2 Matrix{Int64}:\n 1  0\n 1  1\n 1  1\n 1  1\n 1  1\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.backtrack_to_find_breaks","page":"Model Validation","title":"CausalELM.ModelValidation.backtrack_to_find_breaks","text":"backtrack_to_find_breaks(data, num_classes, sums_of_sqs)\n\nDetermine break points from class assignments.\n\nExamples\n\njulia> data = [1, 2, 3, 4, 5]\n[1, 2, 3, 4, 5]\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\njulia> ptr = class_pointers([1, 2, 3, 4, 5], 2, sums_of_squares([1, 2, 3, 4, 5], 2))\n5×2 Matrix{Int64}:\n 1  28\n 1   1\n 1   1\n 1   1\n 1   1\njulia> backtrack_to_find_breaks([1, 2, 3, 4, 5], ptr)\n2-element Vector{Int64}:\n 1\n 4\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.variance","page":"Model Validation","title":"CausalELM.ModelValidation.variance","text":"variance(data)\n\nCalculate the variance of some numbers.\n\nNote this function does not use Besel's correction.\n\nExamples\n\njulia> variance([1, 2, 3, 4, 5])\n2.0\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.best_splits","page":"Model Validation","title":"CausalELM.ModelValidation.best_splits","text":"best_splits(data, num_classes)\n\nFind the best number of splits for Jenks breaks.\n\nThis function finds the best number of splits by finding the number of splits that results      in the greatest decrease in the slope of the line between itself and its GVF and the      next higher number of splits and its GVF. This is the same thing as the elbow method.\n\nExamples\n\njulia> best_splits(collect(1:10), 5)\n10-element Vector{Int64}:\n 1\n 3\n 3\n ⋮\n 3\n 4\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.group_by_class","page":"Model Validation","title":"CausalELM.ModelValidation.group_by_class","text":"group_by_class(data, classes)\n\nGroup data points into vectors such that data points assigned to the same class are in the  same vector.\n\nExamples\n\njulia> group_by_class([1, 2, 3, 4, 5], [1, 1, 1, 2, 3])\n3-element Vector{Vector{Real}}:\n [1, 2, 3]\n [4]\n [5]\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.jenks_breaks","page":"Model Validation","title":"CausalELM.ModelValidation.jenks_breaks","text":"jenks_breaks(data, num_classes)\n\nGenerate Jenks breaks for a vector of real numbers.\n\nExamples\n\njulia> jenks_breaks([1, 2, 3, 4, 5], 3)\n3-element Vector{Int64}:\n 1\n 3\n 4\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.fake_treatments","page":"Model Validation","title":"CausalELM.ModelValidation.fake_treatments","text":"fake_treatments(data, num_classes)\n\nGenerate fake treatment statuses corresponding to the classes assigned by the Jenks breaks  algorithm.\n\nExamples\n\njulia> fake_treatments([1, 2, 3, 4, 5], 4)\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 4\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.sdam","page":"Model Validation","title":"CausalELM.ModelValidation.sdam","text":"sdam(x)\n\nCalculate the sum of squared deviations for array mean for a set of sub arrays.\n\nExamples\n\njulia> sdam([5, 4, 9, 10]) \n26.0\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.scdm","page":"Model Validation","title":"CausalELM.ModelValidation.scdm","text":"sdcm(x)\n\nCalculate the sum of squared deviations for class means for a set of sub arrays.\n\nExamples\n\njulia> scdm([[4], [5, 9, 10]]) \n14.0\n\n\n\n\n\n","category":"function"},{"location":"reference/validation/#CausalELM.ModelValidation.gvf","page":"Model Validation","title":"CausalELM.ModelValidation.gvf","text":"gvf(x)\n\nCalculate the goodness of variance fit for a set of sub vectors.\n\nExamples\n\njulia> gvf([[4, 5], [9, 10]])\n0.96153846153\n\n\n\n\n\n","category":"function"},{"location":"reference/api/#CausalELM","page":"CausalELM","title":"CausalELM","text":"","category":"section"},{"location":"reference/api/","page":"CausalELM","title":"CausalELM","text":"CausalELM","category":"page"},{"location":"reference/api/#CausalELM","page":"CausalELM","title":"CausalELM","text":"Macros, functions, and structs for applying Extreme Learning Machines to causal inference tasks where the counterfactual is unavailable or biased and must be predicted. Provides  macros for event study designs, parametric G-computation, doubly robust estimation, and  metalearners. Additionally, these tasks can be performed with or without L2 penalization and will automatically choose the best number of neurons and L2 penalty. \n\nFor more details on Extreme Learning Machines see:     Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. \"Extreme learning machine: theory      and applications.\" Neurocomputing 70, no. 1-3 (2006): 489-501.\n\n\n\n\n\n","category":"module"},{"location":"guide/its/#Interrupted-Time-Series-Analysis","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Analysis","text":"","category":"section"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"Sometimes we want to know how an outcome variable for a single unit changed after an event  or intervention. For example, if regulators announce sanctions against company A, we might  want to know how the price of stock A changed after the announcement. Since we do not know what the price of Company A's stock would have been if the santions were not announced, we need some way to predict those values. An interrupted time series analysis does this by  using some covariates that are related to the oucome variable but not related to whether the  event happened to predict what would have happened. The estimated effects are the  differences between the predicted post-event counterfactual outcomes and the observed  post-event outcomes, which can also be aggregated to mean or cumulative effects.  Estimating an interrupted time series design in CausalELM consists of three steps.","category":"page"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"For a deeper dive see:     Bernal, James Lopez, Steven Cummins, and Antonio Gasparrini. \"Interrupted time series      regression for the evaluation of public health interventions: a tutorial.\" International      journal of epidemiology 46, no. 1 (2017): 348-355.","category":"page"},{"location":"guide/its/#Step-1:-Initialize-an-interrupted-time-series-estimator","page":"Interrupted Time Series Estimation","title":"Step 1: Initialize an interrupted time series estimator","text":"","category":"section"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"The InterruptedTimeSeries method takes four agruments: an array of pre-event covariates, a  vector of pre-event outcomes, an array of post-event covariates, and a vector of post-event  outcomes.","category":"page"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"# Generate some data to use\nX₀, Y₀, X₁, Y₁ =  rand(1000, 5), rand(1000), rand(100, 5), rand(100)\n\nits = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)","category":"page"},{"location":"guide/its/#Step-2:-Estimate-the-Treatment-Effect","page":"Interrupted Time Series Estimation","title":"Step 2: Estimate the Treatment Effect","text":"","category":"section"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"Estimating the treatment effect only requires one argument: an InterruptedTimeSeries struct.","category":"page"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"# We can also estimate the ATT by passing quantity_of_interest=\"ATT\"\nestimate_causal_effect!(its)","category":"page"},{"location":"guide/its/#Step-3:-Get-a-Summary","page":"Interrupted Time Series Estimation","title":"Step 3: Get a Summary","text":"","category":"section"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"We can get a summary of the model, including a p-value and statndard via asymptotic  randomization inference, by pasing the model to the summarize method.","category":"page"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"summarize(its)","category":"page"},{"location":"guide/its/#Step-4:-Validate-the-Model","page":"Interrupted Time Series Estimation","title":"Step 4: Validate the Model","text":"","category":"section"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"For an interrupted time series design to work well we need to be able to get an unbiased  prediction of the counterfactual outcomes. If the event or intervention effected the  covariates we are using to predict the counterfactual outcomes, then we will not be able to  get unbiased predictions. We can verify this by conducting a Chow Test on the covariates. An ITS design also assumes that any observed effect is due to the hypothesized intervention,  rather than any simultaneous interventions, anticipation of the intervention, or any  intervention that ocurred after the hypothesized intervention. We can use a Wald supremum  test to see if the hypothesized intervention ocurred where there is the largest structural  break in the outcome or if there was a larger, statistically significant break in the  outcome that could confound an ITS analysis. The covariates in an ITS analysis should be  good predictors of the outcome. If this is the case, then adding irrelevant predictors  should not have much of a change on the results of the analysis. We can conduct all these  tests in one line of code.","category":"page"},{"location":"guide/its/","page":"Interrupted Time Series Estimation","title":"Interrupted Time Series Estimation","text":"validate(its)","category":"page"},{"location":"","page":"CausalELM","title":"CausalELM","text":"<div style=\"width:100%; height:15px;;\n        border-radius:6px;text-align:center;\n        color:#1e1e20\">\n    <a class=\"github-button\" href=\"https://github.com/dscolby/CausalELM.jl\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star dscolby/CausalELM.jl on GitHub\" style=\"margin:auto\">Star</a>\n    <script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n</div>","category":"page"},{"location":"","page":"CausalELM","title":"CausalELM","text":"CurrentModule = CausalELM","category":"page"},{"location":"#Overview","page":"CausalELM","title":"Overview","text":"","category":"section"},{"location":"","page":"CausalELM","title":"CausalELM","text":"CausalELM enables Estimation of causal quantities of interest in research designs where a  counterfactual must be predicted and compared to the observed outcomes. More specifically,  CausalELM provides a simple API to execute interupted time series analysis, G-Computation,  and double machine learning as well as estimation of the CATE via S-Learning, T-Learning,  and X-Learning. Once a causal model has beeen estimated, CausalELM's summarize method  provides basic information about the model as well as a p-value and standard error estimated  with approximate randomization inference. One can then validate causal modeling assumptions  for any model with a single call to the validate method. In all of these implementations,  CausalELM predicts the counterfactuals using an Extreme Learning Machine that includes an L2  penalty by default. In this context, ELMs strike a good balance between prediction accuracy,  generalization, ease of implementation, speed, and interpretability. ","category":"page"},{"location":"#Features","page":"CausalELM","title":"Features","text":"","category":"section"},{"location":"","page":"CausalELM","title":"CausalELM","text":"Simple interface enables estimating causal effects in only a few lines of code\nAnalytically derived L2 penalty reduces cross validation time and multicollinearity\nFast automatic cross validation works with longitudinal, panel, and time series data\nIncludes 13 activation functions and allows user-defined activation functions\nSingle interface for continous, binary, and categorical outcome variables\nEstimation of p-values and standard errors via asymptotic randomization inference\nNo dependencies outside of the Julia standard library\nValidate causal modeling assumptiions with one line of code","category":"page"},{"location":"#What's-New?","page":"CausalELM","title":"What's New?","text":"","category":"section"},{"location":"","page":"CausalELM","title":"CausalELM","text":"All functions and methods converted to snake case\nRandomization inference for interrupted time series randomizes all indices\nImplemented validate method to probe assumptions for all estimators and metalearners\nReimplemented cross validation for temporal data\nFixed issue related to recoding variables to calculate validation metrics for cross validation","category":"page"},{"location":"#Comparison-with-Other-Packages","page":"CausalELM","title":"Comparison with Other Packages","text":"","category":"section"},{"location":"","page":"CausalELM","title":"CausalELM","text":"Other packages, mainly EconML, DoWhy, and CausalML, have similar funcitonality. Beides being  written in Julia rather than Python, the main differences between CausalELM and these  libraries are:","category":"page"},{"location":"","page":"CausalELM","title":"CausalELM","text":"CausalELM uses extreme learning machines rather than tree-based or deep learners\nCausalELM performs cross validation during training\nCausalELM performs inference via asymptotic randomization inference rather than    bootstrapping\nCausalELM does not require you to instantiate a model and pass it into a separate class    or struct for training\nCausalELM creates train/test splits automatically\nCausalELM does not have external dependencies: all the functions it uses are in the    Julia standard library","category":"page"},{"location":"#Installation","page":"CausalELM","title":"Installation","text":"","category":"section"},{"location":"","page":"CausalELM","title":"CausalELM","text":"CausalELM requires Julia version 1.7 or greater and can be installed from the REPL as shown  below. ","category":"page"},{"location":"","page":"CausalELM","title":"CausalELM","text":"using Pkg \nPkg.add(\"CausalELM\")","category":"page"},{"location":"guide/metalearners/#Metalearners","page":"Metalearners","title":"Metalearners","text":"","category":"section"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"Instead of knowing the average cuasal effect, we might want to know which units benefit and  which units lose by being exposed to a treatment. For example, a cash transfer program might  motivate some people to work harder and incentivize others to work less. Thus, we might want  to know how the cash transfer program affects individuals instead of it average affect on  the population. To do so, we can use metalearners. Depending on the scenario, we may want to  use an S-learner, a T-learner, or an X-learner. The basic steps to use all three  metalearners are below.","category":"page"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"For a deeper dive on metalearners see:     Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. \"Metalearners for      estimating heterogeneous treatment effects using machine learning.\" Proceedings of the      national academy of sciences 116, no. 10 (2019): 4156-4165.","category":"page"},{"location":"guide/metalearners/#Initialize-a-Metalearner","page":"Metalearners","title":"Initialize a Metalearner","text":"","category":"section"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"S-learners, T-learners, and X-learners all take three arguments: an array of covariates, a  vector of outcomes, and a vector of treatment statuses.","category":"page"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"# Generate data to use\nX, Y, T =  rand(1000, 5), rand(1000), [rand()<0.4 for i in 1:1000]\n\ns_learner = SLearner(X, Y, T)\nt_learner = TLearner(X, Y, T)\nx_learner = XLearner(X, Y, T)","category":"page"},{"location":"guide/metalearners/#Estimate-the-CATE","page":"Metalearners","title":"Estimate the CATE","text":"","category":"section"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"We can estimate the CATE for all the models by passing them to estimatecausaleffect!.","category":"page"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"estimate_causal_effect!(s_learner)\nestimate_causal_effect!(t_learner)\nestimate_causal_effect!(x_learner)","category":"page"},{"location":"guide/metalearners/#Get-a-Summary","page":"Metalearners","title":"Get a Summary","text":"","category":"section"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"We can get a summary of the models that includes p0values and standard errors for the  average treatment effect by passing the models to the summarize method.","category":"page"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"summarize(s_learner)\nsummarize(t_learner)\nsummarize(x_learner)","category":"page"},{"location":"guide/metalearners/#Step-4:-Validate-the-Model","page":"Metalearners","title":"Step 4: Validate the Model","text":"","category":"section"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model's  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  probability of treatment. If the matrix is empty, none of the observations have an estimated  zero probability of treatment, which implies the positivity assumption is satisfied.","category":"page"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"For a thorough review of casual inference assumptions see:     Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and      Francis, 2024. ","category":"page"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"For more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. \"Sensitivity analysis in observational research:      introducing the E-value.\" Annals of internal medicine 167, no. 4 (2017): 268-274.","category":"page"},{"location":"guide/metalearners/","page":"Metalearners","title":"Metalearners","text":"validate(s_learner)\nvalidate(t_learner)\nvalidate(x_learner)","category":"page"}]
}
